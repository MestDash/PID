{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MestDash/PID/blob/main/notebooks/NN_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVZzEVO3yL4b"
      },
      "source": [
        "# Importing the packages\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHZbOyIUQKxo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import random\n",
        "import statistics\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, RobustScaler, QuantileTransformer, PowerTransformer, LabelEncoder\n",
        "from sklearn.impute import KNNImputer, SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, StratifiedShuffleSplit\n",
        "from sklearn.metrics import classification_report, confusion_matrix, balanced_accuracy_score, f1_score, precision_score, recall_score, roc_curve\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers, regularizers, losses, metrics\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input, LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
        "from tensorflow.keras.utils import to_categorical, plot_model, Sequence\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy, SparseCategoricalCrossentropy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some functions"
      ],
      "metadata": {
        "id": "Ls_goHIYqQEd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VA_V1YZJTd8u"
      },
      "outputs": [],
      "source": [
        "def stratified_split(df: pd.DataFrame, test_size: float = 0.2, random_state: int = 17):\n",
        "    X = df.drop(columns=['IUIS', 'IUIS extended', 'PCODE','y'])\n",
        "    y = df['y']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y,\n",
        "        test_size=test_size,\n",
        "        stratify=y,\n",
        "        random_state=random_state\n",
        "    )\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "\n",
        "def labelize(df):\n",
        "    df = df.copy()\n",
        "\n",
        "    def assign_label(row):\n",
        "        # Handle both dash and no-dash variants\n",
        "        if row['IUIS'] in ['No arguments for lymphoid-PID', 'No arguments for lymphoid PID']:\n",
        "            return 'DC'\n",
        "        else:\n",
        "            main_label = row['IUIS'].split(':')[0].strip()\n",
        "            if main_label == 'III':\n",
        "                try:\n",
        "                    first_digit = int(str(row['IUIS extended'])[0])\n",
        "                    if first_digit == 4:\n",
        "                        return 'III.4'\n",
        "                    else:\n",
        "                        return 'III.1-3'\n",
        "                except (ValueError, IndexError):\n",
        "                    return 'III.1-3'  # default if parsing fails\n",
        "            else:\n",
        "                return main_label\n",
        "\n",
        "    df['y'] = df.apply(assign_label, axis=1)\n",
        "    return df\n",
        "\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "N_SPLITS = 5\n",
        "CORR_THRESHOLD = 0.95\n",
        "N_EPOCHS_BIN = 50\n",
        "N_EPOCHS_MULTI = 50\n",
        "BATCH_SIZE = 32\n",
        "SMOTE_IMBALANCE_THRESHOLD = 0.5\n",
        "\n",
        "np.random.seed(RANDOM_STATE)\n",
        "random.seed(RANDOM_STATE)\n",
        "tf.random.set_seed(RANDOM_STATE)\n",
        "\n",
        "# Target classes (canonical order)\n",
        "ALL_CLASSES = [\"DC\", \"I\", \"II\", \"III.1-3\", \"III.4\", \"IV\"]\n",
        "STAGE3_CLASSES = [\"II\", \"III.1-3\", \"III.4\", \"IV\"]  # in this order for softmax head\n",
        "\n",
        "class FeatureFilter(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, corr_threshold=0.95):\n",
        "        self.corr_threshold = corr_threshold\n",
        "        self.to_drop_ = []\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        # Keep only numeric columns\n",
        "        numeric_df = X.select_dtypes(include=[np.number])\n",
        "\n",
        "        # Drop constant features\n",
        "        constant_features = [col for col in numeric_df.columns if numeric_df[col].nunique() <= 1]\n",
        "\n",
        "        # Drop highly correlated features\n",
        "        corr_matrix = numeric_df.corr().abs()\n",
        "        upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "        high_corr = [column for column in upper_triangle.columns if any(upper_triangle[column] > self.corr_threshold)]\n",
        "\n",
        "        # Merge and store\n",
        "        self.to_drop_ = list(set(constant_features + high_corr))\n",
        "        print('These features will be dropped:')\n",
        "        print(self.to_drop_)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X.drop(columns=self.to_drop_, errors='ignore')\n",
        "\n",
        "\n",
        "def build_preprocessor_binary(X_train: pd.DataFrame):\n",
        "    X_train = X_train.copy()\n",
        "    num_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    cat_cols = X_train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "\n",
        "    cat_pipeline = Pipeline(\n",
        "        steps=[\n",
        "            (\"impute\", SimpleImputer(strategy=\"constant\", fill_value=\"NA\")),\n",
        "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    numeric_pipe = Pipeline(steps=[\n",
        "        (\"scale\",     QuantileTransformer(n_quantiles=X_train.shape[0])),\n",
        "        (\"impute\", KNNImputer(n_neighbors=5)),\n",
        "        (\"minmax\",      MinMaxScaler())\n",
        "    ])\n",
        "\n",
        "    pre = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"num\", numeric_pipe, num_cols),\n",
        "            (\"cat\", cat_pipeline, cat_cols)\n",
        "        ],\n",
        "        remainder=\"drop\"\n",
        "    )\n",
        "    pre.fit(X_train)\n",
        "    return pre\n",
        "\n",
        "\n",
        "def build_preprocessor_multi(X_train: pd.DataFrame):\n",
        "    X_train = X_train.copy()\n",
        "    num_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    cat_cols = X_train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "\n",
        "    cat_pipeline = Pipeline(\n",
        "        steps=[\n",
        "            (\"impute\", SimpleImputer(strategy=\"constant\", fill_value=\"NA\")),\n",
        "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    numeric_pipe = Pipeline(steps=[\n",
        "        (\"scale\",     PowerTransformer()),\n",
        "        (\"impute\", KNNImputer(n_neighbors=5))\n",
        "    ])\n",
        "\n",
        "    pre = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"num\", numeric_pipe, num_cols),\n",
        "            (\"cat\", cat_pipeline, cat_cols)\n",
        "        ],\n",
        "        remainder=\"drop\"\n",
        "    )\n",
        "    pre.fit(X_train)\n",
        "    return pre\n",
        "\n",
        "\n",
        "# Custom transformer for conditional log1p\n",
        "class ConditionalLog1p(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.cols_to_transform = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        X = pd.DataFrame(X)\n",
        "        # store which columns need log1p (max > 1)\n",
        "        self.cols_to_transform = [\n",
        "            col for col in X.columns if X[col].max() > 1\n",
        "        ]\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = pd.DataFrame(X).copy()\n",
        "        for col in self.cols_to_transform:\n",
        "            X[col] = np.log1p(X[col])\n",
        "        return X.values\n",
        "\n",
        "def build_stage1_labels(y):\n",
        "    # I vs Rest\n",
        "    return (y == \"I\").astype(int)\n",
        "\n",
        "def build_stage2_labels(y):\n",
        "    # DC vs Rest (but we train Stage2 on the subset y != I)\n",
        "    mask = (y != \"I\")\n",
        "    y2 = (y[mask] == \"DC\").astype(int)\n",
        "    return mask, y2\n",
        "\n",
        "def build_stage3_labels(y):\n",
        "    # Multiclass on {II, IIIa, IIIb, IV}; we train Stage3 on y not in {I, DC}\n",
        "    mask = ~y.isin([\"I\", \"DC\"])\n",
        "    y3 = y[mask]\n",
        "    # Map to indices in STAGE3_CLASSES order\n",
        "    y3_idx = y3.map({c: i for i, c in enumerate(STAGE3_CLASSES)})\n",
        "    return mask, y3_idx\n",
        "\n",
        "def soft_gated_combine_probs(pI, pDC, pStage3_rows, thr_I=0.5, thr_DC=0.5, sharpness=10.0):\n",
        "    \"\"\"\n",
        "    Softly combine probabilities from Stage 1, Stage 2, and Stage 3.\n",
        "\n",
        "    pI:    (n,) probability of \"I\"\n",
        "    pDC:   (n,) probability of \"DC\"\n",
        "    pStage3_rows: (n,4) probabilities over [II, IIIa, IIIb, IV]\n",
        "    thr_I: threshold for \"I\" gating\n",
        "    thr_DC: threshold for \"DC\" gating\n",
        "    sharpness: steepness of the gating sigmoid\n",
        "    Returns:\n",
        "      final_probs: (n, 6) in class order ALL_CLASSES\n",
        "    \"\"\"\n",
        "    def soft_gate(prob, thr, sharpness):\n",
        "        return 1 / (1 + np.exp(-sharpness * (prob - thr)))\n",
        "\n",
        "    n = len(pI)\n",
        "    final = np.zeros((n, 6), dtype=float)\n",
        "    idx = {c: i for i, c in enumerate(ALL_CLASSES)}\n",
        "\n",
        "    for i in range(n):\n",
        "        # --- Soft-threshold scaling with smooth gates ---\n",
        "        g_I  = soft_gate(pI[i], thr_I, sharpness)\n",
        "        g_DC = soft_gate(pDC[i], thr_DC, sharpness)\n",
        "\n",
        "        # Allocate probabilities\n",
        "        p_I = g_I\n",
        "        p_DC = (1 - g_I) * g_DC\n",
        "        rest = (1 - g_I) * (1 - g_DC) * pStage3_rows[i]\n",
        "\n",
        "        final[i, idx[\"I\"]] = p_I\n",
        "        final[i, idx[\"DC\"]] = p_DC\n",
        "        for j, cls in enumerate(STAGE3_CLASSES):\n",
        "            final[i, idx[cls]] = rest[j]\n",
        "\n",
        "        # Normalize\n",
        "        s = final[i].sum()\n",
        "        if s > 0:\n",
        "            final[i] /= s\n",
        "        else:\n",
        "            final[i, :] = 1.0 / len(ALL_CLASSES)\n",
        "\n",
        "    return final\n",
        "\n",
        "\n",
        "def maybe_smote(X_tr, y_tr, is_multiclass=False):\n",
        "    cnt = Counter(y_tr)\n",
        "    if len(cnt) <= 1:\n",
        "        return X_tr, y_tr  # nothing to do\n",
        "    minc, maxc = min(cnt.values()), max(cnt.values())\n",
        "    if (minc / maxc) < SMOTE_IMBALANCE_THRESHOLD:\n",
        "        if is_multiclass:\n",
        "            sm = SMOTE(random_state=RANDOM_STATE)\n",
        "        else:\n",
        "            sm = SMOTE(random_state=RANDOM_STATE)\n",
        "        X_tr, y_tr = sm.fit_resample(X_tr, y_tr)\n",
        "        print(\"SMOTE oversampling:\", Counter(y_tr))\n",
        "    return X_tr, y_tr\n",
        "\n",
        "def plot_confusion_matrix_relative(cm, class_names, title=\"Confusion Matrix (Row-normalized)\"):\n",
        "    # Normalize per row (class)\n",
        "    cm_normalized = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
        "    cm_normalized = np.nan_to_num(cm_normalized)  # replace NaN from divide-by-zero\n",
        "\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    ax = sns.heatmap(\n",
        "        cm_normalized,\n",
        "        annot=cm,\n",
        "        fmt=\"d\",\n",
        "        cmap=\"Blues\",\n",
        "        xticklabels=class_names,\n",
        "        yticklabels=class_names,\n",
        "        cbar=True,\n",
        "        vmin=0.0, vmax=1.0,  # relative per row\n",
        "        linecolor=\"black\",   # border color\n",
        "        linewidths=0.5       # thin border width\n",
        "    )\n",
        "\n",
        "    # Add outer border to match gridlines\n",
        "    ax.add_patch(patches.Rectangle((0, 0), cm.shape[0], cm.shape[1],\n",
        "                                   fill=False, edgecolor='black', lw=0.5, clip_on=False))\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.show()\n",
        "\n",
        "def find_optimal_threshold(y_true, y_prob, metric=\"balanced_accuracy\", num_thresholds=200):\n",
        "    \"\"\"\n",
        "    Find the threshold that maximizes a given metric.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    y_true : array-like\n",
        "        True binary labels (0/1).\n",
        "    y_prob : array-like\n",
        "        Predicted probabilities for the positive class.\n",
        "    metric : str\n",
        "        Metric to optimize. One of {\"balanced_accuracy\", \"f1\", \"precision\", \"recall\"}.\n",
        "    num_thresholds : int\n",
        "        Number of thresholds to evaluate between 0 and 1.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    best_thresh : float\n",
        "        Threshold that maximizes the chosen metric.\n",
        "    best_score : float\n",
        "        Score achieved at the best threshold.\n",
        "    \"\"\"\n",
        "    # Choose metric function\n",
        "    metric_funcs = {\n",
        "        \"balanced_accuracy\": balanced_accuracy_score,\n",
        "        \"f1\": f1_score,\n",
        "        \"precision\": precision_score,\n",
        "        \"recall\": recall_score,\n",
        "    }\n",
        "    if metric not in metric_funcs:\n",
        "        raise ValueError(f\"Unknown metric '{metric}'. Choose from {list(metric_funcs.keys())}\")\n",
        "\n",
        "    best_thresh, best_score = 0.5, -1\n",
        "    thresholds = np.linspace(0.0, 1.0, num_thresholds)\n",
        "\n",
        "    for t in thresholds:\n",
        "        preds = (y_prob >= t).astype(int)\n",
        "        try:\n",
        "            score = metric_funcs[metric](y_true, preds)\n",
        "        except ValueError:\n",
        "            # Can happen if no positive predictions\n",
        "            continue\n",
        "        if score > best_score:\n",
        "            best_thresh, best_score = t, score\n",
        "\n",
        "    print(f\"[Threshold Optimization] Best {metric}: {best_score:.4f} at threshold={best_thresh:.3f}\")\n",
        "    return best_thresh\n",
        "\n",
        "def plot_history(history):\n",
        "    # Plot curves\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Accuracy\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label=\"Train Acc\")\n",
        "    plt.plot(history.history['val_accuracy'], label=\"Val Acc\")\n",
        "    plt.title('Model accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.ylim((0,1.1))\n",
        "\n",
        "    # Loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label=\"Train Loss\")\n",
        "    plt.plot(history.history['val_loss'], label=\"Val Loss\")\n",
        "    plt.title('Model loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(loc='upper left')\n",
        "    #plt.ylim((0,2))\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0TFVGivvZIX"
      },
      "source": [
        "# Scaling benchmark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Z4NoCXcn7mv"
      },
      "outputs": [],
      "source": [
        "# Standard NN for comparison\n",
        "def build_binary(input_dim):\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(input_dim,)),\n",
        "\n",
        "        layers.Dense(64, activation='relu',\n",
        "                     kernel_regularizer=regularizers.l2(1e-4)),\n",
        "        #layers.BatchNormalization(),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        layers.Dense(32, activation='relu',\n",
        "                     kernel_regularizer=regularizers.l2(1e-4)),\n",
        "        #layers.BatchNormalization(),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy', tf.keras.metrics.AUC(name=\"auc\")]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def build_multiclass(input_dim, num_classes):\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(input_dim,)),\n",
        "\n",
        "        layers.Dense(128, activation='relu',\n",
        "                     kernel_regularizer=regularizers.l2(1e-4)),\n",
        "        #layers.BatchNormalization(),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        layers.Dense(96, activation='relu',\n",
        "                     kernel_regularizer=regularizers.l2(1e-4)),\n",
        "        #layers.BatchNormalization(),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        layers.Dense(64, activation='relu',\n",
        "                     kernel_regularizer=regularizers.l2(1e-4)),\n",
        "        #layers.BatchNormalization(),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        layers.Dense(32, activation='relu',\n",
        "                     kernel_regularizer=regularizers.l2(1e-4)),\n",
        "        #layers.BatchNormalization(),\n",
        "        layers.Dropout(0.2),\n",
        "\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=8,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.3,\n",
        "    patience=3,\n",
        "    min_lr=1e-7\n",
        ")\n",
        "\n",
        "callbacks = [early_stop, reduce_lr]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSSUVd88tMHy"
      },
      "outputs": [],
      "source": [
        "# Preprocessing pipeline\n",
        "def build_preprocessor(X_train: pd.DataFrame):\n",
        "    X_train = X_train.copy()\n",
        "    num_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    cat_cols = X_train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "\n",
        "    cat_pipeline = Pipeline(\n",
        "        steps=[\n",
        "            (\"impute\", SimpleImputer(strategy=\"constant\", fill_value=\"NA\")),\n",
        "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    numeric_pipe = Pipeline(steps=[\n",
        "        (\"scale\",     StandardScaler()),\n",
        "        (\"impute\", KNNImputer(n_neighbors=5)),\n",
        "        (\"minmax\",      MinMaxScaler())\n",
        "    ])\n",
        "\n",
        "    pre = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"num\", numeric_pipe, num_cols),\n",
        "            (\"cat\", cat_pipeline, cat_cols)\n",
        "        ],\n",
        "        remainder=\"drop\"\n",
        "    )\n",
        "    pre.fit(X_train)\n",
        "    return pre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8BV09mVqs6e"
      },
      "outputs": [],
      "source": [
        "def run_cascade_cv(X, y, n_splits: int = 5):\n",
        "\n",
        "    stage1_acc, stage2_acc, stage3_acc = [], [], []\n",
        "    fold_reports = []\n",
        "\n",
        "    skf_outer = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_STATE)\n",
        "    print(f\"Starting {n_splits}-split CV (3 train / 1 val / 1 test) on {len(X)} samples...\")\n",
        "\n",
        "    for fold, (trainval_idx, test_idx) in enumerate(skf_outer.split(X, y), 1):\n",
        "        # Split outer: test = 1 fold, trainval = 4 folds\n",
        "        X_trainval, y_trainval = X.iloc[trainval_idx], y.iloc[trainval_idx]\n",
        "        X_test_raw, y_test = X.iloc[test_idx], y.iloc[test_idx]\n",
        "\n",
        "        # Inner split: 3 folds train, 1 fold val\n",
        "        skf_inner = StratifiedKFold(n_splits=4, shuffle=True, random_state=RANDOM_STATE)\n",
        "        inner_train_idx, val_idx = next(skf_inner.split(X_trainval, y_trainval))\n",
        "        X_train_raw, y_train = X_trainval.iloc[inner_train_idx], y_trainval.iloc[inner_train_idx]\n",
        "        X_val_raw, y_val = X_trainval.iloc[val_idx], y_trainval.iloc[val_idx]\n",
        "\n",
        "        print(f\"\\n==================== Fold {fold} ====================\")\n",
        "        print(f\"Train: {len(X_train_raw)}, Val: {len(X_val_raw)}, Test: {len(X_test_raw)}\")\n",
        "\n",
        "        # ---- Feature filter + preprocess (fit only on train)\n",
        "        ff = FeatureFilter(corr_threshold=CORR_THRESHOLD)\n",
        "        ff.fit(X_train_raw)\n",
        "        X_train_ff = ff.transform(X_train_raw)\n",
        "        X_val_ff = ff.transform(X_val_raw)\n",
        "        X_test_ff = ff.transform(X_test_raw)\n",
        "\n",
        "        pre = build_preprocessor(X_train_ff)\n",
        "        X_train_prep = pre.transform(X_train_ff)\n",
        "        X_val_prep = pre.transform(X_val_ff)\n",
        "        X_test_prep = pre.transform(X_test_ff)\n",
        "\n",
        "        in_dim = X_train_prep.shape[1]\n",
        "\n",
        "        # ========= Stage 1: I vs Rest =========\n",
        "        print(\"\\n-- Stage 1 (I vs Rest) --\")\n",
        "        y1_train = build_stage1_labels(y_train)\n",
        "        y1_val   = build_stage1_labels(y_val)\n",
        "        y1_test  = build_stage1_labels(y_test)\n",
        "        stage1_labels = {0: \"Rest\", 1: \"I\"}\n",
        "\n",
        "        cw1 = compute_class_weight(class_weight='balanced', classes=np.unique(y1_train), y=y1_train)\n",
        "        cw1_dict = {int(cls): float(w) for cls, w in zip(np.unique(y1_train), cw1)}\n",
        "        print(\"Class weights (Stage 1):\", cw1_dict)\n",
        "\n",
        "        m1 = build_binary(in_dim)\n",
        "        m1.fit(X_train_prep, y1_train.values,\n",
        "               validation_data=(X_val_prep, y1_val.values),\n",
        "               epochs=50,\n",
        "               batch_size=32,\n",
        "               callbacks=callbacks,\n",
        "               verbose=0,\n",
        "               class_weight=cw1_dict)\n",
        "\n",
        "        p1_val = m1.predict(X_val_prep, verbose=0).ravel()\n",
        "        thresh1 = find_optimal_threshold(y1_val, p1_val)\n",
        "        print(f\"Optimal threshold (Stage 1): {thresh1:.3f}\")\n",
        "\n",
        "        p1_test = m1.predict(X_test_prep, verbose=0).ravel()\n",
        "        pred1_test = (p1_test >= thresh1).astype(int)\n",
        "\n",
        "        print(classification_report(y1_test, pred1_test, digits=4, zero_division=0))\n",
        "        print(\"Balanced Accuracy:\", balanced_accuracy_score(y1_test, pred1_test))\n",
        "        cm1 = confusion_matrix(y1_test, pred1_test)\n",
        "        #plot_confusion_matrix_relative(cm1, class_names=[\"Rest\", \"I\"], title=\"Stage 1 (I vs Rest)\")\n",
        "        stage1_acc.append(balanced_accuracy_score(y1_test, pred1_test))\n",
        "\n",
        "        # ========= Stage 2: DC vs Rest =========\n",
        "        print(\"\\n-- Stage 2 (DC vs Rest) --\")\n",
        "        mask2_train, y2_train = build_stage2_labels(y_train)\n",
        "        mask2_val,   y2_val   = build_stage2_labels(y_val)\n",
        "        mask2_test,  y2_test  = build_stage2_labels(y_test)\n",
        "\n",
        "        X2_train = X_train_prep[mask2_train.values]\n",
        "        X2_val   = X_val_prep[mask2_val.values]\n",
        "        X2_test  = X_test_prep[mask2_test.values]\n",
        "\n",
        "        cw2 = compute_class_weight(class_weight='balanced', classes=np.unique(y2_train), y=y2_train)\n",
        "        cw2_dict = {int(cls): float(w) for cls, w in zip(np.unique(y2_train), cw2)}\n",
        "        print(\"Class weights (Stage 2):\", cw2_dict)\n",
        "\n",
        "        m2 = build_binary(in_dim)\n",
        "        m2.fit(X2_train, y2_train.values,\n",
        "               validation_data=(X2_val, y2_val.values),\n",
        "               epochs=50,\n",
        "               batch_size=32,\n",
        "               callbacks=callbacks,\n",
        "               verbose=0,\n",
        "               class_weight=cw2_dict)\n",
        "\n",
        "        p2_val = m2.predict(X2_val, verbose=0).ravel()\n",
        "        thresh2 = find_optimal_threshold(y2_val, p2_val)\n",
        "        print(f\"Optimal threshold (Stage 2): {thresh2:.3f}\")\n",
        "\n",
        "        p2_test = m2.predict(X2_test, verbose=0).ravel()\n",
        "        pred2_test = (p2_test >= thresh2).astype(int)\n",
        "\n",
        "        print(classification_report(y2_test, pred2_test, digits=4, zero_division=0))\n",
        "        print(\"Balanced Accuracy:\", balanced_accuracy_score(y2_test, pred2_test))\n",
        "        cm2 = confusion_matrix(y2_test, pred2_test)\n",
        "        #plot_confusion_matrix_relative(cm2, class_names=[\"PID\", \"DC\"], title=\"Stage 2 (DC vs Rest)\")\n",
        "        stage2_acc.append(balanced_accuracy_score(y2_test, pred2_test))\n",
        "\n",
        "        # ========= Stage 3: Multiclass =========\n",
        "        print(\"\\n-- Stage 3 (Multiclass) --\")\n",
        "        mask3_train, y3_train = build_stage3_labels(y_train)\n",
        "        mask3_val,   y3_val   = build_stage3_labels(y_val)\n",
        "        mask3_test,  y3_test  = build_stage3_labels(y_test)\n",
        "\n",
        "        X3_train = X_train_prep[mask3_train.values]\n",
        "        X3_val   = X_val_prep[mask3_val.values]\n",
        "        X3_test  = X_test_prep[mask3_test.values]\n",
        "\n",
        "        classes = np.unique(y3_train)\n",
        "        cw3 = compute_class_weight(class_weight='balanced', classes=classes, y=y3_train)\n",
        "        cw3_dict = {int(cls): float(w) for cls, w in zip(classes, cw3)}\n",
        "        print(\"Class weights (Stage 3):\", cw3_dict)\n",
        "\n",
        "        m3 = build_multiclass(in_dim, len(STAGE3_CLASSES))\n",
        "        m3.fit(X3_train, y3_train.values,\n",
        "               validation_data=(X3_val, y3_val.values),\n",
        "               epochs=50,\n",
        "               batch_size=32,\n",
        "               callbacks=callbacks,\n",
        "               verbose=0,\n",
        "               class_weight=cw3_dict)\n",
        "\n",
        "        p3_test = m3.predict(X3_test, verbose=0)\n",
        "        pred3_test = np.argmax(p3_test, axis=1)\n",
        "\n",
        "        print(classification_report(y3_test, pred3_test, digits=4, zero_division=0))\n",
        "        print(\"Balanced Accuracy:\", balanced_accuracy_score(y3_test, pred3_test))\n",
        "        cm3 = confusion_matrix(y3_test, pred3_test)\n",
        "        #plot_confusion_matrix_relative(cm3, class_names=STAGE3_CLASSES, title=\"Stage 3 (Multiclass)\")\n",
        "        stage3_acc.append(balanced_accuracy_score(y3_test, pred3_test))\n",
        "\n",
        "        # ========= Overall predictions (Soft-Gated) =========\n",
        "        pI_all  = m1.predict(X_test_prep, verbose=0).ravel()\n",
        "        pDC_all = m2.predict(X_test_prep, verbose=0).ravel()\n",
        "        pS3_all = m3.predict(X_test_prep, verbose=0)\n",
        "\n",
        "        final_probs = soft_gated_combine_probs(pI_all, pDC_all, pS3_all)\n",
        "        final_idx = np.argmax(final_probs, axis=1)\n",
        "        final_preds = [ALL_CLASSES[i] for i in final_idx]\n",
        "\n",
        "        print(\"\\n== Soft-Gated Overall ==\")\n",
        "        print(classification_report(y_test, final_preds, labels=ALL_CLASSES, digits=4, zero_division=0))\n",
        "        print(\"Balanced Accuracy:\", balanced_accuracy_score(y_test, final_preds))\n",
        "        cm_final = confusion_matrix(y_test, final_preds, labels=ALL_CLASSES)\n",
        "        plot_confusion_matrix_relative(cm_final, class_names=ALL_CLASSES, title=\"Final Soft-Gated Confusion Matrix\")\n",
        "\n",
        "        fold_reports.append({\n",
        "            \"fold\": fold,\n",
        "            \"y_true\": y_test.reset_index(drop=True),\n",
        "            \"y_pred\": pd.Series(final_preds, index=y_test.index).reset_index(drop=True)\n",
        "        })\n",
        "\n",
        "    # ===== Summary =====\n",
        "    y_true_all = pd.concat([fr[\"y_true\"] for fr in fold_reports], axis=0)\n",
        "    y_pred_all = pd.concat([fr[\"y_pred\"] for fr in fold_reports], axis=0)\n",
        "    print(\"\\n==================== CV SUMMARY ====================\")\n",
        "    print(classification_report(y_true_all, y_pred_all, labels=ALL_CLASSES, digits=4, zero_division=0))\n",
        "    print(\"Balanced Accuracy:\", balanced_accuracy_score(y_true_all, y_pred_all))\n",
        "    cm_summary = confusion_matrix(y_true_all, y_pred_all, labels=ALL_CLASSES)\n",
        "    plot_confusion_matrix_relative(cm_summary, class_names=ALL_CLASSES, title=\"CV Summary Confusion Matrix\")\n",
        "\n",
        "    print(\"\\n==================== Accuracies ====================\")\n",
        "    print([float(v) for v in stage1_acc])\n",
        "    print([float(v) for v in stage2_acc])\n",
        "    print([float(v) for v in stage3_acc])\n",
        "    print(\"Mean balanced accuracy:\", [\n",
        "        np.mean(stage1_acc), np.mean(stage2_acc), np.mean(stage3_acc)\n",
        "    ])\n",
        "\n",
        "    return fold_reports, [np.mean(stage1_acc), np.mean(stage2_acc), np.mean(stage3_acc)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yILN7Y-_wVOc",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('df_cluster.csv')\n",
        "df = labelize(df)\n",
        "X_train = df.drop(columns=['IUIS', 'IUIS extended', 'PCODE','y'])\n",
        "y_train = df['y']\n",
        "\n",
        "CORR_THRESHOLD = 0.9\n",
        "'''\n",
        "def run_multiple_cv(X, y, n_splits: int = N_SPLITS, n_repeats: int = 5):\n",
        "    all_reports = []\n",
        "    all_b_acc = []\n",
        "\n",
        "    for repeat in range(1, n_repeats + 1):\n",
        "        print(f\"\\n\\n==================== REPEAT {repeat}/{n_repeats} ====================\")\n",
        "\n",
        "        fold_reports, b_acc_means = run_cascade_cv(X, y, n_splits=n_splits)\n",
        "        all_reports.extend(fold_reports)\n",
        "        all_b_acc.append(b_acc_means)\n",
        "\n",
        "    print(\"\\n==================== FINAL SUMMARY ====================\")\n",
        "    print(\"All balanced accuracies:\", all_b_acc)\n",
        "    #print(\"Mean balanced accuracy:\", statistics.mean(all_b_acc))\n",
        "    #se = np.std(all_b_acc, ddof=1) / np.sqrt(len(all_b_acc))\n",
        "    #print(\"Standard Error:\", se)\n",
        "\n",
        "    return all_reports, all_b_acc\n",
        "'''\n",
        "all_reports, all_b_acc = run_multiple_flat_cv(X_train, y_train, n_splits=5, n_repeats=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwvnP0Ije602",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('df_cluster.csv')\n",
        "df = labelize(df)\n",
        "X_train = df.drop(columns=['IUIS', 'IUIS extended', 'PCODE','y'])\n",
        "y_train = df['y']\n",
        "\n",
        "# Preprocessing pipeline\n",
        "def build_preprocessor(X_train: pd.DataFrame):\n",
        "    X_train = X_train.copy()\n",
        "    num_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    cat_cols = X_train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "\n",
        "    cat_pipeline = Pipeline(\n",
        "        steps=[\n",
        "            (\"impute\", SimpleImputer(strategy=\"constant\", fill_value=\"NA\")),\n",
        "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    numeric_pipe = Pipeline(steps=[\n",
        "        (\"scale\",     RobustScaler()),\n",
        "        (\"impute\", KNNImputer(n_neighbors=5)),\n",
        "        (\"minmax\",      MinMaxScaler())\n",
        "    ])\n",
        "\n",
        "    pre = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"num\", numeric_pipe, num_cols),\n",
        "            (\"cat\", cat_pipeline, cat_cols)\n",
        "        ],\n",
        "        remainder=\"drop\"\n",
        "    )\n",
        "    pre.fit(X_train)\n",
        "    return pre\n",
        "\n",
        "all_reports, all_b_acc = run_multiple_flat_cv(X_train, y_train, n_splits=5, n_repeats=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DW0CSikPnlI7",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('df_cluster.csv')\n",
        "df = labelize(df)\n",
        "X_train = df.drop(columns=['IUIS', 'IUIS extended', 'PCODE','y'])\n",
        "y_train = df['y']\n",
        "\n",
        "# Preprocessing pipeline\n",
        "def build_preprocessor(X_train: pd.DataFrame):\n",
        "    X_train = X_train.copy()\n",
        "    num_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    cat_cols = X_train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "\n",
        "    cat_pipeline = Pipeline(\n",
        "        steps=[\n",
        "            (\"impute\", SimpleImputer(strategy=\"constant\", fill_value=\"NA\")),\n",
        "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    numeric_pipe = Pipeline(steps=[\n",
        "        (\"scale\",     QuantileTransformer()),\n",
        "        (\"impute\", KNNImputer(n_neighbors=5)),\n",
        "        (\"minmax\",      MinMaxScaler())\n",
        "    ])\n",
        "\n",
        "    pre = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"num\", numeric_pipe, num_cols),\n",
        "            (\"cat\", cat_pipeline, cat_cols)\n",
        "        ],\n",
        "        remainder=\"drop\"\n",
        "    )\n",
        "    pre.fit(X_train)\n",
        "    return pre\n",
        "\n",
        "all_reports, all_b_acc = run_multiple_flat_cv(X_train, y_train, n_splits=5, n_repeats=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jB4KnhippumK",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('df_cluster.csv')\n",
        "df = labelize(df)\n",
        "X_train = df.drop(columns=['IUIS', 'IUIS extended', 'PCODE','y'])\n",
        "y_train = df['y']\n",
        "\n",
        "# Preprocessing pipeline\n",
        "def build_preprocessor(X_train: pd.DataFrame):\n",
        "    X_train = X_train.copy()\n",
        "    num_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    cat_cols = X_train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "\n",
        "    cat_pipeline = Pipeline(\n",
        "        steps=[\n",
        "            (\"impute\", SimpleImputer(strategy=\"constant\", fill_value=\"NA\")),\n",
        "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    numeric_pipe = Pipeline(steps=[\n",
        "        (\"scale\",     PowerTransformer()),\n",
        "        (\"impute\", KNNImputer(n_neighbors=5)),\n",
        "        (\"minmax\",      MinMaxScaler())\n",
        "    ])\n",
        "\n",
        "    pre = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"num\", numeric_pipe, num_cols),\n",
        "            (\"cat\", cat_pipeline, cat_cols)\n",
        "        ],\n",
        "        remainder=\"drop\"\n",
        "    )\n",
        "    pre.fit(X_train)\n",
        "    return pre\n",
        "\n",
        "all_reports, all_b_acc = run_multiple_flat_cv(X_train, y_train, n_splits=5, n_repeats=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6ehollmtLuD",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('df_cluster.csv')\n",
        "df = labelize(df)\n",
        "X_train = df.drop(columns=['IUIS', 'IUIS extended', 'PCODE','y'])\n",
        "y_train = df['y']\n",
        "\n",
        "# Preprocessing pipeline\n",
        "def build_preprocessor(X_train: pd.DataFrame):\n",
        "    X_train = X_train.copy()\n",
        "    num_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    cat_cols = X_train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "\n",
        "    cat_pipeline = Pipeline(\n",
        "        steps=[\n",
        "            (\"impute\", SimpleImputer(strategy=\"constant\", fill_value=\"NA\")),\n",
        "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    numeric_pipe = Pipeline(steps=[\n",
        "        (\"scale\",     ConditionalLog1p()),\n",
        "        (\"impute\", KNNImputer(n_neighbors=5)),\n",
        "        (\"minmax\",      MinMaxScaler())\n",
        "    ])\n",
        "\n",
        "    pre = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"num\", numeric_pipe, num_cols),\n",
        "            (\"cat\", cat_pipeline, cat_cols)\n",
        "        ],\n",
        "        remainder=\"drop\"\n",
        "    )\n",
        "    pre.fit(X_train)\n",
        "    return pre\n",
        "\n",
        "all_reports, all_b_acc = run_multiple_flat_cv(X_train, y_train, n_splits=5, n_repeats=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlRmIqztFFpj"
      },
      "outputs": [],
      "source": [
        "def build_flat_nn(input_dim, num_classes):\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(input_dim,)),\n",
        "        layers.Dense(256, activation='relu',\n",
        "                     kernel_regularizer=regularizers.l2(1e-4)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(256, activation='relu',\n",
        "                     kernel_regularizer=regularizers.l2(1e-4)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        layers.Dense(128, activation='relu',\n",
        "                     kernel_regularizer=regularizers.l2(1e-4)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        layers.Dense(64, activation='relu',\n",
        "                     kernel_regularizer=regularizers.l2(1e-4)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        layers.Dense(32, activation='relu',\n",
        "                     kernel_regularizer=regularizers.l2(1e-4)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.2),\n",
        "\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor=\"val_loss\", patience=8, restore_best_weights=True, verbose=0),\n",
        "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.3, patience=3, min_lr=1e-7, verbose=0),\n",
        "]\n",
        "\n",
        "def run_flat_cv(X, y, n_splits: int = 5):  # force 5 splits (3 train, 1 val, 1 test)\n",
        "\n",
        "    # Encode labels\n",
        "    le = LabelEncoder()\n",
        "    y_encoded = le.fit_transform(y)\n",
        "    class_names = le.classes_\n",
        "\n",
        "    skf_outer = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_STATE)\n",
        "    fold_reports = []\n",
        "\n",
        "    print(f\"Starting {n_splits}-fold CV (3-train / 1-val / 1-test) on {len(X)} samples...\")\n",
        "\n",
        "    for fold, (trainval_idx, test_idx) in enumerate(skf_outer.split(X, y_encoded), 1):\n",
        "        print(f\"\\n==================== Outer Fold {fold} ====================\")\n",
        "\n",
        "        # Split into outer train+val vs test\n",
        "        X_trainval, X_test = X.iloc[trainval_idx].copy(), X.iloc[test_idx].copy()\n",
        "        y_trainval, y_test = y_encoded[trainval_idx], y_encoded[test_idx]\n",
        "\n",
        "        # Now split trainval into inner-train and inner-val (3 folds vs 1 fold)\n",
        "        skf_inner = StratifiedKFold(n_splits=4, shuffle=True, random_state=RANDOM_STATE)\n",
        "        inner_train_idx, inner_val_idx = next(skf_inner.split(X_trainval, y_trainval))\n",
        "\n",
        "        X_train, X_val = X_trainval.iloc[inner_train_idx], X_trainval.iloc[inner_val_idx]\n",
        "        y_train, y_val = y_trainval[inner_train_idx], y_trainval[inner_val_idx]\n",
        "\n",
        "        # ---- Feature filter\n",
        "        ff = FeatureFilter(corr_threshold=CORR_THRESHOLD)\n",
        "        ff.fit(X_train)\n",
        "        X_train_ff = ff.transform(X_train)\n",
        "        X_val_ff = ff.transform(X_val)\n",
        "        X_test_ff = ff.transform(X_test)\n",
        "\n",
        "        pre = build_preprocessor(X_train_ff)\n",
        "        X_train_prep = pre.transform(X_train_ff)\n",
        "        X_val_prep = pre.transform(X_val_ff)\n",
        "        X_test_prep = pre.transform(X_test_ff)\n",
        "\n",
        "        input_dim = X_train_prep.shape[1]\n",
        "\n",
        "        # ---- Class weights\n",
        "        cw = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_train), y=y_train)\n",
        "        cw_dict = {cls: w for cls, w in zip(np.unique(y_train), cw)}\n",
        "\n",
        "        # ---- Build and train model\n",
        "        model = build_flat_nn(input_dim, num_classes=6)\n",
        "        model.fit(X_train_prep, y_train,\n",
        "                  validation_data=(X_val_prep, y_val),\n",
        "                  epochs=50,\n",
        "                  batch_size=32,\n",
        "                  callbacks=callbacks,\n",
        "                  verbose=0,\n",
        "                  class_weight=cw_dict\n",
        "                  )\n",
        "\n",
        "        # ---- Predictions on outer test fold\n",
        "        y_pred_prob = model.predict(X_test_prep, verbose=0)\n",
        "        y_pred_idx = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "        # Decode to original string labels\n",
        "        y_test_labels = le.inverse_transform(y_test)\n",
        "        y_pred_labels = le.inverse_transform(y_pred_idx)\n",
        "\n",
        "        print(classification_report(y_test_labels, y_pred_labels, labels=class_names, digits=4, zero_division=0))\n",
        "        print(\"Balanced Accuracy:\", balanced_accuracy_score(y_test_labels, y_pred_labels))\n",
        "        cm = confusion_matrix(y_test_labels, y_pred_labels, labels=class_names)\n",
        "        print(\"Confusion Matrix:\\n\", cm)\n",
        "        #plot_confusion_matrix_relative(cm, class_names=class_names, title=f\"Outer Fold {fold} Confusion Matrix\")\n",
        "\n",
        "        fold_reports.append({\n",
        "            \"fold\": fold,\n",
        "            \"y_true\": pd.Series(y_test_labels).reset_index(drop=True),\n",
        "            \"y_pred\": pd.Series(y_pred_labels).reset_index(drop=True)\n",
        "        })\n",
        "\n",
        "    # ===== CV summary =====\n",
        "    y_true_all = pd.concat([fr[\"y_true\"] for fr in fold_reports], axis=0)\n",
        "    y_pred_all = pd.concat([fr[\"y_pred\"] for fr in fold_reports], axis=0)\n",
        "\n",
        "    print(\"\\n==================== CV SUMMARY ====================\")\n",
        "    print(classification_report(y_true_all, y_pred_all, labels=class_names, digits=4, zero_division=0))\n",
        "    print(\"Balanced Accuracy:\", balanced_accuracy_score(y_true_all, y_pred_all))\n",
        "    cm_summary = confusion_matrix(y_true_all, y_pred_all, labels=class_names)\n",
        "    print(\"Confusion Matrix:\\n\", cm_summary)\n",
        "    #plot_confusion_matrix_relative(cm_summary, class_names=class_names, title=\"CV Summary Confusion Matrix\")\n",
        "    overall_bACC = balanced_accuracy_score(y_true_all, y_pred_all)\n",
        "    return fold_reports, overall_bACC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0fu6t5jGu50"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('df_cluster.csv')\n",
        "df = labelize(df)\n",
        "X_train = df.drop(columns=['IUIS', 'IUIS extended', 'PCODE','y'])\n",
        "y_train = df['y']\n",
        "\n",
        "CORR_THRESHOLD = 0.9\n",
        "\n",
        "def run_multiple_flat_cv(X, y, n_splits: int = N_SPLITS, n_repeats: int = 5):\n",
        "    all_reports = []\n",
        "    all_b_acc = []\n",
        "\n",
        "    for repeat in range(1, n_repeats + 1):\n",
        "        print(f\"\\n\\n==================== REPEAT {repeat}/{n_repeats} ====================\")\n",
        "\n",
        "        fold_reports, b_acc = run_flat_cv(X, y, n_splits=n_splits)\n",
        "        all_reports.extend(fold_reports)\n",
        "        all_b_acc.append(b_acc)\n",
        "\n",
        "    print(\"\\n==================== FINAL SUMMARY ====================\")\n",
        "    print(\"All balanced accuracies:\", all_b_acc)\n",
        "    #print(\"Mean balanced accuracy:\", statistics.mean(all_b_acc))\n",
        "    #se = np.std(all_b_acc, ddof=1) / np.sqrt(len(all_b_acc))\n",
        "    #print(\"Standard Error:\", se)\n",
        "\n",
        "    return all_reports, all_b_acc\n",
        "\n",
        "all_reports, all_b_acc = run_multiple_flat_cv(X_train, y_train, n_splits=5, n_repeats=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOjIqGo-qqNR"
      },
      "source": [
        "# Optimized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsIRemoLBBiW"
      },
      "outputs": [],
      "source": [
        "# Preprocessing pipeline\n",
        "def build_preprocessor(X_train: pd.DataFrame, stage):\n",
        "    X_train = X_train.copy()\n",
        "    num_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    cat_cols = X_train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "\n",
        "    cat_pipeline = Pipeline(\n",
        "        steps=[\n",
        "            (\"impute\", SimpleImputer(strategy=\"constant\", fill_value=\"NA\")),\n",
        "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    if stage == 1:\n",
        "        numeric_pipe = Pipeline(steps=[\n",
        "            (\"scale\",     QuantileTransformer(n_quantiles=X_train.shape[0])),\n",
        "            (\"impute\", KNNImputer(n_neighbors=5)),\n",
        "            (\"minmax\",      MinMaxScaler())\n",
        "        ])\n",
        "\n",
        "    elif stage == 2:\n",
        "        numeric_pipe = Pipeline(steps=[\n",
        "            (\"scale\",     ConditionalLog1p()),\n",
        "            (\"impute\", KNNImputer(n_neighbors=5)),\n",
        "            (\"minmax\",      MinMaxScaler())\n",
        "        ])\n",
        "\n",
        "    elif stage == 3:\n",
        "        numeric_pipe = Pipeline(steps=[\n",
        "            (\"scale\",     PowerTransformer()),\n",
        "            (\"impute\", KNNImputer(n_neighbors=5))\n",
        "        ])\n",
        "\n",
        "    elif stage == 4:\n",
        "        numeric_pipe = Pipeline(steps=[\n",
        "            (\"scale\",     RobustScaler()),\n",
        "            (\"impute\", KNNImputer(n_neighbors=5)),\n",
        "            (\"minmax\",      MinMaxScaler())\n",
        "        ])\n",
        "\n",
        "    pre = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"num\", numeric_pipe, num_cols),\n",
        "            (\"cat\", cat_pipeline, cat_cols)\n",
        "        ],\n",
        "        remainder=\"drop\"\n",
        "    )\n",
        "    pre.fit(X_train)\n",
        "    return pre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kYLRFe5BagW"
      },
      "outputs": [],
      "source": [
        "def create_model(input_dim, stage, params, is_binary):\n",
        "    units = params[\"units\"]\n",
        "    learning_rate = params[\"learning_rate\"]\n",
        "    dropout_rate = params[\"dropout_rate\"]\n",
        "    num_hidden_layers = params[\"num_hidden_layers\"]\n",
        "    l2_reg = params[\"l2_reg\"]\n",
        "    activation = params[\"activation\"]\n",
        "    optimizer_name = params[\"optimizer\"]\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(input_dim,)))\n",
        "\n",
        "    # Hidden layers\n",
        "    for _ in range(num_hidden_layers - 1):\n",
        "        model.add(Dense(units, activation=activation, kernel_regularizer=l2(l2_reg)))\n",
        "        if not stage == 1 or stage == 3:\n",
        "            model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout_rate))\n",
        "\n",
        "    if stage == 1 or stage == 2:\n",
        "        model.add(Dense(64, activation=activation, kernel_regularizer=l2(l2_reg)))\n",
        "        if stage == 1:\n",
        "            model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout_rate))\n",
        "        model.add(Dense(32, activation=activation, kernel_regularizer=l2(l2_reg)))\n",
        "        if stage == 1:\n",
        "            model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout_rate))\n",
        "    else:\n",
        "        model.add(Dense(128, activation=activation, kernel_regularizer=l2(l2_reg)))\n",
        "        if stage == 3:\n",
        "            model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout_rate))\n",
        "        model.add(Dense(64, activation=activation, kernel_regularizer=l2(l2_reg)))\n",
        "        if stage == 3:\n",
        "            model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout_rate))\n",
        "        model.add(Dense(32, activation=activation, kernel_regularizer=l2(l2_reg)))\n",
        "        if stage == 3:\n",
        "            model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout_rate))\n",
        "\n",
        "    # Output layer\n",
        "    if is_binary:\n",
        "        model.add(Dense(1, activation=\"sigmoid\", kernel_regularizer=l2(l2_reg)))\n",
        "        loss_fn = \"binary_crossentropy\"\n",
        "    else:\n",
        "        if stage == 3:\n",
        "            model.add(Dense(4, activation=\"softmax\", kernel_regularizer=l2(l2_reg)))\n",
        "            loss_fn = \"sparse_categorical_crossentropy\"\n",
        "        elif stage == 4:\n",
        "            model.add(Dense(6, activation=\"softmax\", kernel_regularizer=l2(l2_reg)))\n",
        "            loss_fn = \"sparse_categorical_crossentropy\"\n",
        "\n",
        "    # Select optimizer\n",
        "    if optimizer_name == \"adam\":\n",
        "        optimizer = Adam(learning_rate=learning_rate)\n",
        "    elif optimizer_name == \"sgd\":\n",
        "        optimizer = SGD(learning_rate=learning_rate, momentum=0.9)\n",
        "    elif optimizer_name == \"rmsprop\":\n",
        "        optimizer = RMSprop(learning_rate=learning_rate)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown optimizer: {optimizer_name}\")\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=loss_fn,\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "    #filename = f\"stage_{stage}.h5\"\n",
        "    #model.save(filename)\n",
        "\n",
        "    return model\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=8,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.3,\n",
        "    patience=3,\n",
        "    min_lr=1e-7\n",
        ")\n",
        "\n",
        "callbacks = [early_stop, reduce_lr]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIaN6ROC4PIT"
      },
      "outputs": [],
      "source": [
        "def balanced_accuracy_from_cm(cm: np.ndarray) -> float:\n",
        "    \"\"\"\n",
        "    Compute balanced accuracy directly from a confusion matrix.\n",
        "    Works for both binary and multiclass cases.\n",
        "    \"\"\"\n",
        "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
        "        recalls = np.diag(cm) / cm.sum(axis=1)\n",
        "        recalls = recalls[~np.isnan(recalls)]  # drop NaNs if a class has no samples\n",
        "    return np.mean(recalls)\n",
        "\n",
        "\n",
        "def run_cascade_cv(X, y, n_splits: int = 5):\n",
        "\n",
        "    stage1_acc, stage2_acc, stage3_acc = [], [], []\n",
        "    fold_reports = []\n",
        "\n",
        "    # ===== Initialize accumulators =====\n",
        "    cm1_total = np.zeros((2, 2), dtype=int)  # Stage 1: binary Rest vs I\n",
        "    cm2_total = np.zeros((2, 2), dtype=int)  # Stage 2: binary PID vs DC\n",
        "    cm3_total = np.zeros((len(STAGE3_CLASSES), len(STAGE3_CLASSES)), dtype=int)  # Stage 3: multiclass\n",
        "    cm_final_total = np.zeros((len(ALL_CLASSES), len(ALL_CLASSES)), dtype=int)   # Soft-gated final\n",
        "\n",
        "    skf_outer = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_STATE)\n",
        "    print(f\"Starting {n_splits}-split CV (3 train / 1 val / 1 test) on {len(X)} samples...\")\n",
        "\n",
        "    for fold, (trainval_idx, test_idx) in enumerate(skf_outer.split(X, y), 1):\n",
        "        # Split outer: test = 1 fold, trainval = 4 folds\n",
        "        X_trainval, y_trainval = X.iloc[trainval_idx], y.iloc[trainval_idx]\n",
        "        X_test_raw, y_test = X.iloc[test_idx], y.iloc[test_idx]\n",
        "\n",
        "        # Inner split: 3 folds train, 1 fold val\n",
        "        skf_inner = StratifiedKFold(n_splits=4, shuffle=True, random_state=RANDOM_STATE)\n",
        "        inner_train_idx, val_idx = next(skf_inner.split(X_trainval, y_trainval))\n",
        "        X_train_raw, y_train = X_trainval.iloc[inner_train_idx], y_trainval.iloc[inner_train_idx]\n",
        "        X_val_raw, y_val = X_trainval.iloc[val_idx], y_trainval.iloc[val_idx]\n",
        "\n",
        "        print(f\"\\n==================== Fold {fold} ====================\")\n",
        "        print(f\"Train: {len(X_train_raw)}, Val: {len(X_val_raw)}, Test: {len(X_test_raw)}\")\n",
        "\n",
        "        # ---- Feature filter + preprocess (fit only on train)\n",
        "        ff = FeatureFilter(corr_threshold=CORR_THRESHOLD)\n",
        "        ff.fit(X_train_raw)\n",
        "        X_train_ff = ff.transform(X_train_raw)\n",
        "        X_val_ff = ff.transform(X_val_raw)\n",
        "        X_test_ff = ff.transform(X_test_raw)\n",
        "\n",
        "        # ========= Stage 1: I vs Rest =========\n",
        "        stage = 1\n",
        "        pre1 = build_preprocessor(X_train_ff, stage)\n",
        "        X1_train_prep = pre1.transform(X_train_ff)\n",
        "        X1_val_prep = pre1.transform(X_val_ff)\n",
        "        X1_test_prep = pre1.transform(X_test_ff)\n",
        "        in_dim = X1_train_prep.shape[1]\n",
        "\n",
        "        print(\"\\n-- Stage 1 (I vs Rest) --\")\n",
        "        y1_train = build_stage1_labels(y_train)\n",
        "        y1_val   = build_stage1_labels(y_val)\n",
        "        y1_test  = build_stage1_labels(y_test)\n",
        "\n",
        "        cw1 = compute_class_weight(class_weight='balanced', classes=np.unique(y1_train), y=y1_train)\n",
        "        cw1_dict = {int(cls): float(w) for cls, w in zip(np.unique(y1_train), cw1)}\n",
        "\n",
        "        m1 = create_model(in_dim, stage, params1, is_binary=True)\n",
        "        m1.fit(X1_train_prep, y1_train.values,\n",
        "               validation_data=(X1_val_prep, y1_val.values),\n",
        "               epochs=params1[\"epochs\"],\n",
        "               batch_size=params1[\"batch_size\"],\n",
        "               callbacks=callbacks,\n",
        "               verbose=0,\n",
        "               class_weight=cw1_dict)\n",
        "\n",
        "        p1_val = m1.predict(X1_val_prep, verbose=0).ravel()\n",
        "        thresh1 = find_optimal_threshold(y1_val, p1_val)\n",
        "        #if thresh1 >= 0.5:\n",
        "        #    thresh1 = 0.4\n",
        "\n",
        "        p1_test = m1.predict(X1_test_prep, verbose=0).ravel()\n",
        "        pred1_test = (p1_test >= thresh1).astype(int)\n",
        "\n",
        "        print(classification_report(y1_test, pred1_test, digits=4, zero_division=0))\n",
        "        print(\"Balanced Accuracy:\", balanced_accuracy_score(y1_test, pred1_test))\n",
        "        cm1 = confusion_matrix(y1_test, pred1_test, labels=[0, 1])\n",
        "        plot_confusion_matrix_relative(cm1, class_names=[\"Rest\", \"I\"], title=\"Stage 1 (I vs Rest)\")\n",
        "        cm1_total += cm1\n",
        "        stage1_acc.append(balanced_accuracy_score(y1_test, pred1_test))\n",
        "\n",
        "        # ========= Stage 2: DC vs Rest =========\n",
        "        stage = 2\n",
        "        pre2 = build_preprocessor(X_train_ff, stage)\n",
        "        X2_train_prep = pre2.transform(X_train_ff)\n",
        "        X2_val_prep = pre2.transform(X_val_ff)\n",
        "        X2_test_prep = pre2.transform(X_test_ff)\n",
        "\n",
        "        print(\"\\n-- Stage 2 (DC vs Rest) --\")\n",
        "        mask2_train, y2_train = build_stage2_labels(y_train)\n",
        "        mask2_val,   y2_val   = build_stage2_labels(y_val)\n",
        "        mask2_test,  y2_test  = build_stage2_labels(y_test)\n",
        "\n",
        "        X2_train = X2_train_prep[mask2_train.values]\n",
        "        X2_val   = X2_val_prep[mask2_val.values]\n",
        "        X2_test  = X2_test_prep[mask2_test.values]\n",
        "\n",
        "        cw2 = compute_class_weight(class_weight='balanced', classes=np.unique(y2_train), y=y2_train)\n",
        "        cw2_dict = {int(cls): float(w) for cls, w in zip(np.unique(y2_train), cw2)}\n",
        "\n",
        "        m2 = create_model(in_dim, stage, params2, is_binary=True)\n",
        "        m2.fit(X2_train, y2_train.values,\n",
        "               validation_data=(X2_val, y2_val.values),\n",
        "               epochs=params2[\"epochs\"],\n",
        "               batch_size=params2[\"batch_size\"],\n",
        "               callbacks=callbacks,\n",
        "               verbose=0,\n",
        "               class_weight=cw2_dict)\n",
        "\n",
        "        p2_val = m2.predict(X2_val, verbose=0).ravel()\n",
        "        thresh2 = find_optimal_threshold(y2_val, p2_val)\n",
        "\n",
        "        p2_test = m2.predict(X2_test, verbose=0).ravel()\n",
        "        pred2_test = (p2_test >= thresh2).astype(int)\n",
        "\n",
        "        print(classification_report(y2_test, pred2_test, digits=4, zero_division=0))\n",
        "        print(\"Balanced Accuracy:\", balanced_accuracy_score(y2_test, pred2_test))\n",
        "        cm2 = confusion_matrix(y2_test, pred2_test, labels=[0, 1])\n",
        "        plot_confusion_matrix_relative(cm2, class_names=[\"PID\", \"DC\"], title=\"Stage 2 (DC vs Rest)\")\n",
        "        cm2_total += cm2\n",
        "        stage2_acc.append(balanced_accuracy_score(y2_test, pred2_test))\n",
        "\n",
        "        # ========= Stage 3: Multiclass =========\n",
        "        stage = 3\n",
        "        pre3 = build_preprocessor(X_train_ff, stage)\n",
        "        X3_train_prep = pre3.transform(X_train_ff)\n",
        "        X3_val_prep = pre3.transform(X_val_ff)\n",
        "        X3_test_prep = pre3.transform(X_test_ff)\n",
        "\n",
        "        print(\"\\n-- Stage 3 (Multiclass) --\")\n",
        "        mask3_train, y3_train = build_stage3_labels(y_train)\n",
        "        mask3_val,   y3_val   = build_stage3_labels(y_val)\n",
        "        mask3_test,  y3_test  = build_stage3_labels(y_test)\n",
        "\n",
        "        X3_train = X3_train_prep[mask3_train.values]\n",
        "        X3_val   = X3_val_prep[mask3_val.values]\n",
        "        X3_test  = X3_test_prep[mask3_test.values]\n",
        "\n",
        "        classes = np.unique(y3_train)\n",
        "\n",
        "        #ros = RandomOverSampler(random_state=17)\n",
        "        #X3_train_res, y3_train_res = ros.fit_resample(X3_train, y3_train)\n",
        "\n",
        "        cw3 = compute_class_weight(class_weight='balanced', classes=classes, y=y3_train)\n",
        "        cw3_dict = {int(cls): float(w) for cls, w in zip(classes, cw3)}\n",
        "\n",
        "        m3 = create_model(in_dim, stage, params3, is_binary=False)\n",
        "        m3.fit(X3_train, y3_train.values,\n",
        "               validation_data=(X3_val, y3_val.values),\n",
        "               epochs=params3[\"epochs\"],\n",
        "               batch_size=params3[\"batch_size\"],\n",
        "               callbacks=callbacks,\n",
        "               verbose=0,\n",
        "               class_weight=cw3_dict)\n",
        "\n",
        "        p3_test = m3.predict(X3_test, verbose=0)\n",
        "        pred3_test = np.argmax(p3_test, axis=1)\n",
        "\n",
        "        print(classification_report(y3_test, pred3_test, digits=4, zero_division=0))\n",
        "        print(\"Balanced Accuracy:\", balanced_accuracy_score(y3_test, pred3_test))\n",
        "        cm3 = confusion_matrix(y3_test, pred3_test, labels=range(len(STAGE3_CLASSES)))\n",
        "        plot_confusion_matrix_relative(cm3, class_names=STAGE3_CLASSES, title=\"Stage 3 (Multiclass)\")\n",
        "        cm3_total += cm3\n",
        "        stage3_acc.append(balanced_accuracy_score(y3_test, pred3_test))\n",
        "\n",
        "        # ========= Overall predictions (Soft-Gated) =========\n",
        "        pI_all  = m1.predict(X1_test_prep, verbose=0).ravel()\n",
        "        pDC_all = m2.predict(X2_test_prep, verbose=0).ravel()\n",
        "        pS3_all = m3.predict(X3_test_prep, verbose=0)\n",
        "\n",
        "        final_probs = soft_gated_combine_probs(pI_all, pDC_all, pS3_all, thresh1, thresh2)\n",
        "        final_idx = np.argmax(final_probs, axis=1)\n",
        "        final_preds = [ALL_CLASSES[i] for i in final_idx]\n",
        "\n",
        "        print(\"\\n== Soft-Gated Overall ==\")\n",
        "        print(classification_report(y_test, final_preds, labels=ALL_CLASSES, digits=4, zero_division=0))\n",
        "        print(\"Balanced Accuracy:\", balanced_accuracy_score(y_test, final_preds))\n",
        "        cm_final = confusion_matrix(y_test, final_preds, labels=ALL_CLASSES)\n",
        "        plot_confusion_matrix_relative(cm_final, class_names=ALL_CLASSES, title=\"Final Soft-Gated Confusion Matrix\")\n",
        "        cm_final_total += cm_final\n",
        "\n",
        "        fold_reports.append({\n",
        "            \"fold\": fold,\n",
        "            \"y_true\": y_test.reset_index(drop=True),\n",
        "            \"y_pred\": pd.Series(final_preds, index=y_test.index).reset_index(drop=True)\n",
        "        })\n",
        "\n",
        "    # ===== After CV: show aggregated confusion matrices =====\n",
        "    print(\"\\n==================== AGGREGATED CONFUSION MATRICES ====================\")\n",
        "    plot_confusion_matrix_relative(cm1_total, class_names=[\"Rest\", \"I\"], title=\"Stage 1 (Total)\")\n",
        "    plot_confusion_matrix_relative(cm2_total, class_names=[\"PID\", \"DC\"], title=\"Stage 2 (Total)\")\n",
        "    plot_confusion_matrix_relative(cm3_total, class_names=STAGE3_CLASSES, title=\"Stage 3 (Total)\")\n",
        "    plot_confusion_matrix_relative(cm_final_total, class_names=ALL_CLASSES, title=\"Final Soft-Gated (Total)\")\n",
        "\n",
        "    # ===== Compute balanced accuracy from aggregated confusion matrices =====\n",
        "    agg_stage1_acc = balanced_accuracy_from_cm(cm1_total)\n",
        "    agg_stage2_acc = balanced_accuracy_from_cm(cm2_total)\n",
        "    agg_stage3_acc = balanced_accuracy_from_cm(cm3_total)\n",
        "    agg_final_acc  = balanced_accuracy_from_cm(cm_final_total)\n",
        "\n",
        "    # ===== Summary =====\n",
        "    y_true_all = pd.concat([fr[\"y_true\"] for fr in fold_reports], axis=0)\n",
        "    y_pred_all = pd.concat([fr[\"y_pred\"] for fr in fold_reports], axis=0)\n",
        "    print(\"\\n==================== CV SUMMARY ====================\")\n",
        "    print(classification_report(y_true_all, y_pred_all, labels=ALL_CLASSES, digits=4, zero_division=0))\n",
        "    print(\"Balanced Accuracy (Final Soft-Gated, aggregated):\", agg_final_acc)\n",
        "\n",
        "    print(\"\\n==================== Accuracies ====================\")\n",
        "    print(\"Per-fold balanced accuracy:\")\n",
        "    print(\"Stage 1:\", [float(v) for v in stage1_acc])\n",
        "    print(\"Stage 2:\", [float(v) for v in stage2_acc])\n",
        "    print(\"Stage 3:\", [float(v) for v in stage3_acc])\n",
        "    print(\"Mean per-fold balanced accuracy:\", [\n",
        "        np.mean(stage1_acc), np.mean(stage2_acc), np.mean(stage3_acc)\n",
        "    ])\n",
        "    print(\"Aggregated balanced accuracy:\")\n",
        "    print(\"Stage 1:\", agg_stage1_acc)\n",
        "    print(\"Stage 2:\", agg_stage2_acc)\n",
        "    print(\"Stage 3:\", agg_stage3_acc)\n",
        "    print(\"Final Soft-Gated:\", agg_final_acc)\n",
        "\n",
        "    return fold_reports, {\n",
        "        \"mean_per_fold\": [np.mean(stage1_acc), np.mean(stage2_acc), np.mean(stage3_acc)],\n",
        "        \"aggregated\": [agg_stage1_acc, agg_stage2_acc, agg_stage3_acc, agg_final_acc]\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exNJ7zj6FTLT"
      },
      "outputs": [],
      "source": [
        "def run_multiple_cvs(X, y, n_runs: int = 5, n_splits: int = 5):\n",
        "    all_results = []\n",
        "\n",
        "    for run in range(1, n_runs + 1):\n",
        "        print(f\"\\n\\n==================== CV RUN {run}/{n_runs} ====================\")\n",
        "        fold_reports, summary = run_cascade_cv(X, y, n_splits=n_splits)\n",
        "        all_results.append(summary)\n",
        "\n",
        "    # Summarize variance across runs\n",
        "    mean_per_fold = np.array([res[\"mean_per_fold\"] for res in all_results])\n",
        "    aggregated = np.array([res[\"aggregated\"] for res in all_results])\n",
        "\n",
        "    print(\"\\n\\n==================== MULTI-RUN SUMMARY ====================\")\n",
        "    print(\"Mean per-fold balanced accuracy (across runs):\")\n",
        "    print(\"Stage 1: mean =\", mean_per_fold[:,0].mean(), \", std =\", mean_per_fold[:,0].std())\n",
        "    print(\"Stage 2: mean =\", mean_per_fold[:,1].mean(), \", std =\", mean_per_fold[:,1].std())\n",
        "    print(\"Stage 3: mean =\", mean_per_fold[:,2].mean(), \", std =\", mean_per_fold[:,2].std())\n",
        "\n",
        "    print(\"\\nAggregated balanced accuracy (across runs):\")\n",
        "    print(\"Stage 1: mean =\", aggregated[:,0].mean(), \", std =\", aggregated[:,0].std())\n",
        "    print(\"Stage 2: mean =\", aggregated[:,1].mean(), \", std =\", aggregated[:,1].std())\n",
        "    print(\"Stage 3: mean =\", aggregated[:,2].mean(), \", std =\", aggregated[:,2].std())\n",
        "    print(\"Final Soft-Gated: mean =\", aggregated[:,3].mean(), \", std =\", aggregated[:,3].std())\n",
        "    return all_results\n",
        "\n",
        "params1 = {'units': 239, 'learning_rate': 0.0016, 'dropout_rate': 0.364, 'num_hidden_layers': 1, 'batch_size': 110, 'epochs': 46, 'l2_reg': 0.0039, 'activation': \"selu\", 'optimizer': \"sgd\"}\n",
        "params2 = {'units': 167, 'learning_rate': 0.0054, 'dropout_rate': 0.3488, 'num_hidden_layers': 1, 'batch_size': 21, 'epochs': 50, 'l2_reg': 0.00612, 'activation': 'selu', 'optimizer': 'rmsprop'}\n",
        "params3 = {'units': 86, 'learning_rate': 0.01, 'dropout_rate': 0.2, 'num_hidden_layers': 3, 'batch_size': 71, 'epochs': 86, 'l2_reg': 0.000001, 'activation': \"selu\", 'optimizer': \"rmsprop\"}\n",
        "params4 = {'units': 150, 'learning_rate': 0.01, 'dropout_rate': 0.5, 'num_hidden_layers': 1, 'batch_size': 84, 'epochs': 88, 'l2_reg': 0.01, 'activation': \"selu\", 'optimizer': \"sgd\"}\n",
        "\n",
        "train = pd.read_csv('df_cluster.csv')\n",
        "test = pd.read_csv('df_cluster_VAL.csv')\n",
        "\n",
        "train = labelize(train)\n",
        "test = labelize(test)\n",
        "test.columns = train.columns # some column names have slighlty different names\n",
        "\n",
        "CORR_THRESHOLD = 0.9\n",
        "\n",
        "X_train = train.drop(columns=['IUIS', 'IUIS extended', 'PCODE','y'])\n",
        "y_train = train['y']\n",
        "X_test = test.drop(columns=['IUIS', 'IUIS extended', 'PCODE','y'])\n",
        "y_test = test['y']\n",
        "\n",
        "run_multiple_cvs(X_train, y_train, n_runs=5, n_splits=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4u1Rb35JXakk"
      },
      "outputs": [],
      "source": [
        "def run_multi_cv(X, y, n_splits: int = 5):  # force 5 splits (3 train, 1 val, 1 test)\n",
        "\n",
        "    # Encode labels\n",
        "    le = LabelEncoder()\n",
        "    y_encoded = le.fit_transform(y)\n",
        "    class_names = le.classes_\n",
        "\n",
        "    skf_outer = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_STATE)\n",
        "    fold_reports = []\n",
        "\n",
        "    print(f\"Starting {n_splits}-fold CV (3-train / 1-val / 1-test) on {len(X)} samples...\")\n",
        "\n",
        "    for fold, (trainval_idx, test_idx) in enumerate(skf_outer.split(X, y_encoded), 1):\n",
        "        print(f\"\\n==================== Outer Fold {fold} ====================\")\n",
        "\n",
        "        # Split into outer train+val vs test\n",
        "        X_trainval, X_test = X.iloc[trainval_idx].copy(), X.iloc[test_idx].copy()\n",
        "        y_trainval, y_test = y_encoded[trainval_idx], y_encoded[test_idx]\n",
        "\n",
        "        # Now split trainval into inner-train and inner-val (3 folds vs 1 fold)\n",
        "        skf_inner = StratifiedKFold(n_splits=4, shuffle=True, random_state=RANDOM_STATE)\n",
        "        inner_train_idx, inner_val_idx = next(skf_inner.split(X_trainval, y_trainval))\n",
        "\n",
        "        X_train, X_val = X_trainval.iloc[inner_train_idx], X_trainval.iloc[inner_val_idx]\n",
        "        y_train, y_val = y_trainval[inner_train_idx], y_trainval[inner_val_idx]\n",
        "\n",
        "        # ---- Feature filter\n",
        "        ff = FeatureFilter(corr_threshold=CORR_THRESHOLD)\n",
        "        ff.fit(X_train)\n",
        "        X_train_ff = ff.transform(X_train)\n",
        "        X_val_ff = ff.transform(X_val)\n",
        "        X_test_ff = ff.transform(X_test)\n",
        "\n",
        "        pre4 = build_preprocessor(X_train_ff, 4)\n",
        "        X_train_prep = pre4.transform(X_train_ff)\n",
        "        X_val_prep = pre4.transform(X_val_ff)\n",
        "        X_test_prep = pre4.transform(X_test_ff)\n",
        "\n",
        "        input_dim = X_train_prep.shape[1]\n",
        "\n",
        "        # ---- Class weights\n",
        "        cw = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_train), y=y_train)\n",
        "        cw_dict = {cls: w for cls, w in zip(np.unique(y_train), cw)}\n",
        "\n",
        "        # ---- Build and train model\n",
        "        model = create_model(input_dim, 4, params4, is_binary=False)\n",
        "        model.fit(X_train_prep, y_train,\n",
        "                  validation_data=(X_val_prep, y_val),\n",
        "                  epochs=int(params4[\"epochs\"]),\n",
        "                  batch_size=int(params4[\"batch_size\"]),\n",
        "                  callbacks=callbacks,\n",
        "                  verbose=0,\n",
        "                  class_weight=cw_dict\n",
        "                  )\n",
        "\n",
        "        # ---- Predictions on outer test fold\n",
        "        y_pred_prob = model.predict(X_test_prep, verbose=0)\n",
        "        y_pred_idx = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "        # Decode to original string labels\n",
        "        y_test_labels = le.inverse_transform(y_test)\n",
        "        y_pred_labels = le.inverse_transform(y_pred_idx)\n",
        "\n",
        "        print(classification_report(y_test_labels, y_pred_labels, labels=class_names, digits=4, zero_division=0))\n",
        "        print(\"Balanced Accuracy:\", balanced_accuracy_score(y_test_labels, y_pred_labels))\n",
        "        cm = confusion_matrix(y_test_labels, y_pred_labels, labels=class_names)\n",
        "        print(\"Confusion Matrix:\\n\", cm)\n",
        "        plot_confusion_matrix_relative(cm, class_names=class_names, title=f\"Outer Fold {fold} Confusion Matrix\")\n",
        "\n",
        "        fold_reports.append({\n",
        "            \"fold\": fold,\n",
        "            \"y_true\": pd.Series(y_test_labels).reset_index(drop=True),\n",
        "            \"y_pred\": pd.Series(y_pred_labels).reset_index(drop=True)\n",
        "        })\n",
        "\n",
        "    # ===== CV summary =====\n",
        "    y_true_all = pd.concat([fr[\"y_true\"] for fr in fold_reports], axis=0)\n",
        "    y_pred_all = pd.concat([fr[\"y_pred\"] for fr in fold_reports], axis=0)\n",
        "\n",
        "    print(\"\\n==================== CV SUMMARY ====================\")\n",
        "    print(classification_report(y_true_all, y_pred_all, labels=class_names, digits=4, zero_division=0))\n",
        "    print(\"Balanced Accuracy:\", balanced_accuracy_score(y_true_all, y_pred_all))\n",
        "    cm_summary = confusion_matrix(y_true_all, y_pred_all, labels=class_names)\n",
        "    print(\"Confusion Matrix:\\n\", cm_summary)\n",
        "    plot_confusion_matrix_relative(cm_summary, class_names=class_names, title=\"CV Summary Confusion Matrix\")\n",
        "    overall_bACC = balanced_accuracy_score(y_true_all, y_pred_all)\n",
        "    return fold_reports, overall_bACC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTd2RTwWd2-b",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "params4 = {'units': 150, 'learning_rate': 0.01, 'dropout_rate': 0.5, 'num_hidden_layers': 1, 'batch_size': 84, 'epochs': 88, 'l2_reg': 0.01, 'activation': \"selu\", 'optimizer': \"sgd\"}\n",
        "\n",
        "df = pd.read_csv('df_cluster.csv')\n",
        "df = labelize(df)\n",
        "X_train = df.drop(columns=['IUIS', 'IUIS extended', 'PCODE','y'])\n",
        "y_train = df['y']\n",
        "\n",
        "CORR_THRESHOLD = 0.9\n",
        "\n",
        "def run_multiple_cv(X, y, n_splits: int = N_SPLITS, n_repeats: int = 5):\n",
        "    all_reports = []\n",
        "    all_b_acc = []\n",
        "\n",
        "    for repeat in range(1, n_repeats + 1):\n",
        "        print(f\"\\n\\n==================== REPEAT {repeat}/{n_repeats} ====================\")\n",
        "\n",
        "        fold_reports, b_acc = run_multi_cv(X, y, n_splits=n_splits)\n",
        "        all_reports.extend(fold_reports)\n",
        "        all_b_acc.append(b_acc)\n",
        "\n",
        "    print(\"\\n==================== FINAL SUMMARY ====================\")\n",
        "    print(\"All balanced accuracies:\", all_b_acc)\n",
        "    print(\"Mean balanced accuracy:\", statistics.mean(all_b_acc))\n",
        "    se = np.std(all_b_acc, ddof=1) / np.sqrt(len(all_b_acc))\n",
        "    print(\"Standard Error:\", se)\n",
        "\n",
        "    return all_reports, all_b_acc\n",
        "\n",
        "all_reports, all_b_acc = run_multiple_cv(X_train, y_train, n_splits=5, n_repeats=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bxj1fWMcx4O"
      },
      "source": [
        "# CV with Balanced Batching\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLHJeU3uc1ek"
      },
      "outputs": [],
      "source": [
        "class BalancedBatchGenerator(Sequence):\n",
        "    \"\"\"\n",
        "    Generates balanced batches from (X, y) for imbalanced classification problems.\n",
        "    Each batch includes approximately equal samples from each class.\n",
        "    \"\"\"\n",
        "    def __init__(self, X, y, batch_size=32):\n",
        "        self.X = np.asarray(X)\n",
        "        self.y = np.asarray(y)\n",
        "        self.batch_size = batch_size\n",
        "        self.classes, self.class_indices = np.unique(self.y, return_inverse=True)\n",
        "        self.indices_per_class = {cls: np.where(self.y == cls)[0] for cls in self.classes}\n",
        "        self.samples_per_class = max(1, batch_size // len(self.classes))\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.y) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_indices = []\n",
        "        for cls in self.classes:\n",
        "            cls_indices = np.random.choice(\n",
        "                self.indices_per_class[cls],\n",
        "                size=self.samples_per_class,\n",
        "                replace=len(self.indices_per_class[cls]) < self.samples_per_class\n",
        "            )\n",
        "            batch_indices.extend(cls_indices)\n",
        "        np.random.shuffle(batch_indices)\n",
        "        X_batch = self.X[batch_indices]\n",
        "        y_batch = self.y[batch_indices]\n",
        "        return X_batch, y_batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwG5D7Odc25l"
      },
      "outputs": [],
      "source": [
        "def balanced_accuracy_from_cm(cm: np.ndarray) -> float:\n",
        "    \"\"\"\n",
        "    Compute balanced accuracy directly from a confusion matrix.\n",
        "    Works for both binary and multiclass cases.\n",
        "    \"\"\"\n",
        "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
        "        recalls = np.diag(cm) / cm.sum(axis=1)\n",
        "        recalls = recalls[~np.isnan(recalls)]  # drop NaNs if a class has no samples\n",
        "    return np.mean(recalls)\n",
        "\n",
        "\n",
        "def run_cascade_cv(X, y, n_splits: int = 5):\n",
        "\n",
        "    stage1_acc, stage2_acc, stage3_acc = [], [], []\n",
        "    fold_reports = []\n",
        "\n",
        "    # ===== Initialize accumulators =====\n",
        "    cm1_total = np.zeros((2, 2), dtype=int)  # Stage 1: binary Rest vs I\n",
        "    cm2_total = np.zeros((2, 2), dtype=int)  # Stage 2: binary PID vs DC\n",
        "    cm3_total = np.zeros((len(STAGE3_CLASSES), len(STAGE3_CLASSES)), dtype=int)  # Stage 3: multiclass\n",
        "    cm_final_total = np.zeros((len(ALL_CLASSES), len(ALL_CLASSES)), dtype=int)   # Soft-gated final\n",
        "\n",
        "    skf_outer = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_STATE)\n",
        "    print(f\"Starting {n_splits}-split CV (3 train / 1 val / 1 test) on {len(X)} samples...\")\n",
        "\n",
        "    for fold, (trainval_idx, test_idx) in enumerate(skf_outer.split(X, y), 1):\n",
        "        # Split outer: test = 1 fold, trainval = 4 folds\n",
        "        X_trainval, y_trainval = X.iloc[trainval_idx], y.iloc[trainval_idx]\n",
        "        X_test_raw, y_test = X.iloc[test_idx], y.iloc[test_idx]\n",
        "\n",
        "        # Inner split: 3 folds train, 1 fold val\n",
        "        skf_inner = StratifiedKFold(n_splits=4, shuffle=True, random_state=RANDOM_STATE)\n",
        "        inner_train_idx, val_idx = next(skf_inner.split(X_trainval, y_trainval))\n",
        "        X_train_raw, y_train = X_trainval.iloc[inner_train_idx], y_trainval.iloc[inner_train_idx]\n",
        "        X_val_raw, y_val = X_trainval.iloc[val_idx], y_trainval.iloc[val_idx]\n",
        "\n",
        "        print(f\"\\n==================== Fold {fold} ====================\")\n",
        "        print(f\"Train: {len(X_train_raw)}, Val: {len(X_val_raw)}, Test: {len(X_test_raw)}\")\n",
        "\n",
        "        # ---- Feature filter + preprocess (fit only on train)\n",
        "        ff = FeatureFilter(corr_threshold=CORR_THRESHOLD)\n",
        "        ff.fit(X_train_raw)\n",
        "        X_train_ff = ff.transform(X_train_raw)\n",
        "        X_val_ff = ff.transform(X_val_raw)\n",
        "        X_test_ff = ff.transform(X_test_raw)\n",
        "\n",
        "        # ========= Stage 1: I vs Rest =========\n",
        "        stage = 1\n",
        "        pre1 = build_preprocessor(X_train_ff, stage)\n",
        "        X1_train_prep = pre1.transform(X_train_ff)\n",
        "        X1_val_prep = pre1.transform(X_val_ff)\n",
        "        X1_test_prep = pre1.transform(X_test_ff)\n",
        "        in_dim = X1_train_prep.shape[1]\n",
        "\n",
        "        print(\"\\n-- Stage 1 (I vs Rest) --\")\n",
        "        y1_train = build_stage1_labels(y_train)\n",
        "        y1_val   = build_stage1_labels(y_val)\n",
        "        y1_test  = build_stage1_labels(y_test)\n",
        "\n",
        "        #cw1 = compute_class_weight(class_weight='balanced', classes=np.unique(y1_train), y=y1_train)\n",
        "        #cw1_dict = {int(cls): float(w) for cls, w in zip(np.unique(y1_train), cw1)}\n",
        "\n",
        "        m1 = create_model(in_dim, stage, params1, is_binary=True)\n",
        "\n",
        "        gen1 = BalancedBatchGenerator(X1_train_prep, y1_train.values, batch_size=params1[\"batch_size\"])\n",
        "        m1.fit(gen1,\n",
        "               validation_data=(X1_val_prep, y1_val.values),\n",
        "               epochs=params1[\"epochs\"],\n",
        "               callbacks=callbacks,\n",
        "               verbose=0)\n",
        "               #class_weight=cw1_dict)\n",
        "\n",
        "        p1_val = m1.predict(X1_val_prep, verbose=0).ravel()\n",
        "        thresh1 = find_optimal_threshold(y1_val, p1_val)\n",
        "        #if thresh1 >= 0.5:\n",
        "        #    thresh1 = 0.4\n",
        "\n",
        "        p1_test = m1.predict(X1_test_prep, verbose=0).ravel()\n",
        "        pred1_test = (p1_test >= thresh1).astype(int)\n",
        "\n",
        "        print(classification_report(y1_test, pred1_test, digits=4, zero_division=0))\n",
        "        print(\"Balanced Accuracy:\", balanced_accuracy_score(y1_test, pred1_test))\n",
        "        cm1 = confusion_matrix(y1_test, pred1_test, labels=[0, 1])\n",
        "        plot_confusion_matrix_relative(cm1, class_names=[\"Rest\", \"I\"], title=\"Stage 1 (I vs Rest)\")\n",
        "        cm1_total += cm1\n",
        "        stage1_acc.append(balanced_accuracy_score(y1_test, pred1_test))\n",
        "\n",
        "        # ========= Stage 2: DC vs Rest =========\n",
        "        stage = 2\n",
        "        pre2 = build_preprocessor(X_train_ff, stage)\n",
        "        X2_train_prep = pre2.transform(X_train_ff)\n",
        "        X2_val_prep = pre2.transform(X_val_ff)\n",
        "        X2_test_prep = pre2.transform(X_test_ff)\n",
        "\n",
        "        print(\"\\n-- Stage 2 (DC vs Rest) --\")\n",
        "        mask2_train, y2_train = build_stage2_labels(y_train)\n",
        "        mask2_val,   y2_val   = build_stage2_labels(y_val)\n",
        "        mask2_test,  y2_test  = build_stage2_labels(y_test)\n",
        "\n",
        "        X2_train = X2_train_prep[mask2_train.values]\n",
        "        X2_val   = X2_val_prep[mask2_val.values]\n",
        "        X2_test  = X2_test_prep[mask2_test.values]\n",
        "\n",
        "        #cw2 = compute_class_weight(class_weight='balanced', classes=np.unique(y2_train), y=y2_train)\n",
        "        #cw2_dict = {int(cls): float(w) for cls, w in zip(np.unique(y2_train), cw2)}\n",
        "\n",
        "        m2 = create_model(in_dim, stage, params2, is_binary=True)\n",
        "\n",
        "        gen2 = BalancedBatchGenerator(X2_train, y2_train.values, batch_size=params2[\"batch_size\"])\n",
        "        m2.fit(gen2,\n",
        "               validation_data=(X2_val, y2_val.values),\n",
        "               epochs=params2[\"epochs\"],\n",
        "               callbacks=callbacks,\n",
        "               verbose=0)\n",
        "               #class_weight=cw2_dict)\n",
        "\n",
        "\n",
        "        p2_val = m2.predict(X2_val, verbose=0).ravel()\n",
        "        thresh2 = find_optimal_threshold(y2_val, p2_val)\n",
        "\n",
        "        p2_test = m2.predict(X2_test, verbose=0).ravel()\n",
        "        pred2_test = (p2_test >= thresh2).astype(int)\n",
        "\n",
        "        print(classification_report(y2_test, pred2_test, digits=4, zero_division=0))\n",
        "        print(\"Balanced Accuracy:\", balanced_accuracy_score(y2_test, pred2_test))\n",
        "        cm2 = confusion_matrix(y2_test, pred2_test, labels=[0, 1])\n",
        "        plot_confusion_matrix_relative(cm2, class_names=[\"PID\", \"DC\"], title=\"Stage 2 (DC vs Rest)\")\n",
        "        cm2_total += cm2\n",
        "        stage2_acc.append(balanced_accuracy_score(y2_test, pred2_test))\n",
        "\n",
        "        # ========= Stage 3: Multiclass =========\n",
        "        stage = 3\n",
        "        pre3 = build_preprocessor(X_train_ff, stage)\n",
        "        X3_train_prep = pre3.transform(X_train_ff)\n",
        "        X3_val_prep = pre3.transform(X_val_ff)\n",
        "        X3_test_prep = pre3.transform(X_test_ff)\n",
        "\n",
        "        print(\"\\n-- Stage 3 (Multiclass) --\")\n",
        "        mask3_train, y3_train = build_stage3_labels(y_train)\n",
        "        mask3_val,   y3_val   = build_stage3_labels(y_val)\n",
        "        mask3_test,  y3_test  = build_stage3_labels(y_test)\n",
        "\n",
        "        X3_train = X3_train_prep[mask3_train.values]\n",
        "        X3_val   = X3_val_prep[mask3_val.values]\n",
        "        X3_test  = X3_test_prep[mask3_test.values]\n",
        "\n",
        "        classes = np.unique(y3_train)\n",
        "\n",
        "        #cw3 = compute_class_weight(class_weight='balanced', classes=classes, y=y3_train)\n",
        "        #cw3_dict = {int(cls): float(w) for cls, w in zip(classes, cw3)}\n",
        "\n",
        "        m3 = create_model(in_dim, stage, params3, is_binary=False)\n",
        "\n",
        "        gen3 = BalancedBatchGenerator(X3_train, y3_train.values, batch_size=params3[\"batch_size\"])\n",
        "        m3.fit(gen3,\n",
        "               validation_data=(X3_val, y3_val.values),\n",
        "               epochs=params3[\"epochs\"],\n",
        "               callbacks=callbacks,\n",
        "               verbose=0)\n",
        "               #class_weight=cw3_dict)\n",
        "\n",
        "\n",
        "        p3_test = m3.predict(X3_test, verbose=0)\n",
        "        pred3_test = np.argmax(p3_test, axis=1)\n",
        "\n",
        "        print(classification_report(y3_test, pred3_test, digits=4, zero_division=0))\n",
        "        print(\"Balanced Accuracy:\", balanced_accuracy_score(y3_test, pred3_test))\n",
        "        cm3 = confusion_matrix(y3_test, pred3_test, labels=range(len(STAGE3_CLASSES)))\n",
        "        plot_confusion_matrix_relative(cm3, class_names=STAGE3_CLASSES, title=\"Stage 3 (Multiclass)\")\n",
        "        cm3_total += cm3\n",
        "        stage3_acc.append(balanced_accuracy_score(y3_test, pred3_test))\n",
        "\n",
        "        # ========= Overall predictions (Soft-Gated) =========\n",
        "        pI_all  = m1.predict(X1_test_prep, verbose=0).ravel()\n",
        "        pDC_all = m2.predict(X2_test_prep, verbose=0).ravel()\n",
        "        pS3_all = m3.predict(X3_test_prep, verbose=0)\n",
        "\n",
        "        final_probs = soft_gated_combine_probs(pI_all, pDC_all, pS3_all, thresh1, thresh2)\n",
        "        final_idx = np.argmax(final_probs, axis=1)\n",
        "        final_preds = [ALL_CLASSES[i] for i in final_idx]\n",
        "\n",
        "        print(\"\\n== Soft-Gated Overall ==\")\n",
        "        print(classification_report(y_test, final_preds, labels=ALL_CLASSES, digits=4, zero_division=0))\n",
        "        print(\"Balanced Accuracy:\", balanced_accuracy_score(y_test, final_preds))\n",
        "        cm_final = confusion_matrix(y_test, final_preds, labels=ALL_CLASSES)\n",
        "        plot_confusion_matrix_relative(cm_final, class_names=ALL_CLASSES, title=\"Final Soft-Gated Confusion Matrix\")\n",
        "        cm_final_total += cm_final\n",
        "\n",
        "        fold_reports.append({\n",
        "            \"fold\": fold,\n",
        "            \"y_true\": y_test.reset_index(drop=True),\n",
        "            \"y_pred\": pd.Series(final_preds, index=y_test.index).reset_index(drop=True)\n",
        "        })\n",
        "\n",
        "    # ===== After CV: show aggregated confusion matrices =====\n",
        "    print(\"\\n==================== AGGREGATED CONFUSION MATRICES ====================\")\n",
        "    plot_confusion_matrix_relative(cm1_total, class_names=[\"Rest\", \"I\"], title=\"Stage 1 (Total)\")\n",
        "    plot_confusion_matrix_relative(cm2_total, class_names=[\"PID\", \"DC\"], title=\"Stage 2 (Total)\")\n",
        "    plot_confusion_matrix_relative(cm3_total, class_names=STAGE3_CLASSES, title=\"Stage 3 (Total)\")\n",
        "    plot_confusion_matrix_relative(cm_final_total, class_names=ALL_CLASSES, title=\"Final Soft-Gated (Total)\")\n",
        "\n",
        "    # ===== Compute balanced accuracy from aggregated confusion matrices =====\n",
        "    agg_stage1_acc = balanced_accuracy_from_cm(cm1_total)\n",
        "    agg_stage2_acc = balanced_accuracy_from_cm(cm2_total)\n",
        "    agg_stage3_acc = balanced_accuracy_from_cm(cm3_total)\n",
        "    agg_final_acc  = balanced_accuracy_from_cm(cm_final_total)\n",
        "\n",
        "    # ===== Summary =====\n",
        "    y_true_all = pd.concat([fr[\"y_true\"] for fr in fold_reports], axis=0)\n",
        "    y_pred_all = pd.concat([fr[\"y_pred\"] for fr in fold_reports], axis=0)\n",
        "    print(\"\\n==================== CV SUMMARY ====================\")\n",
        "    print(classification_report(y_true_all, y_pred_all, labels=ALL_CLASSES, digits=4, zero_division=0))\n",
        "    print(\"Balanced Accuracy (Final Soft-Gated, aggregated):\", agg_final_acc)\n",
        "\n",
        "    print(\"\\n==================== Accuracies ====================\")\n",
        "    print(\"Per-fold balanced accuracy:\")\n",
        "    print(\"Stage 1:\", [float(v) for v in stage1_acc])\n",
        "    print(\"Stage 2:\", [float(v) for v in stage2_acc])\n",
        "    print(\"Stage 3:\", [float(v) for v in stage3_acc])\n",
        "    print(\"Mean per-fold balanced accuracy:\", [\n",
        "        np.mean(stage1_acc), np.mean(stage2_acc), np.mean(stage3_acc)\n",
        "    ])\n",
        "    print(\"Aggregated balanced accuracy:\")\n",
        "    print(\"Stage 1:\", agg_stage1_acc)\n",
        "    print(\"Stage 2:\", agg_stage2_acc)\n",
        "    print(\"Stage 3:\", agg_stage3_acc)\n",
        "    print(\"Final Soft-Gated:\", agg_final_acc)\n",
        "\n",
        "    return fold_reports, {\n",
        "        \"mean_per_fold\": [np.mean(stage1_acc), np.mean(stage2_acc), np.mean(stage3_acc)],\n",
        "        \"aggregated\": [agg_stage1_acc, agg_stage2_acc, agg_stage3_acc, agg_final_acc]\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1J4ESijePoX",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "def run_multiple_cvs(X, y, n_runs: int = 5, n_splits: int = 5):\n",
        "    all_results = []\n",
        "\n",
        "    for run in range(1, n_runs + 1):\n",
        "        print(f\"\\n\\n==================== CV RUN {run}/{n_runs} ====================\")\n",
        "        fold_reports, summary = run_cascade_cv(X, y, n_splits=n_splits)\n",
        "        all_results.append(summary)\n",
        "\n",
        "    # Summarize variance across runs\n",
        "    mean_per_fold = np.array([res[\"mean_per_fold\"] for res in all_results])\n",
        "    aggregated = np.array([res[\"aggregated\"] for res in all_results])\n",
        "\n",
        "    print(\"\\n\\n==================== MULTI-RUN SUMMARY ====================\")\n",
        "    print(\"Mean per-fold balanced accuracy (across runs):\")\n",
        "    print(\"Stage 1: mean =\", mean_per_fold[:,0].mean(), \", std =\", mean_per_fold[:,0].std())\n",
        "    print(\"Stage 2: mean =\", mean_per_fold[:,1].mean(), \", std =\", mean_per_fold[:,1].std())\n",
        "    print(\"Stage 3: mean =\", mean_per_fold[:,2].mean(), \", std =\", mean_per_fold[:,2].std())\n",
        "\n",
        "    print(\"\\nAggregated balanced accuracy (across runs):\")\n",
        "    print(\"Stage 1: mean =\", aggregated[:,0].mean(), \", std =\", aggregated[:,0].std())\n",
        "    print(\"Stage 2: mean =\", aggregated[:,1].mean(), \", std =\", aggregated[:,1].std())\n",
        "    print(\"Stage 3: mean =\", aggregated[:,2].mean(), \", std =\", aggregated[:,2].std())\n",
        "    print(\"Final Soft-Gated: mean =\", aggregated[:,3].mean(), \", std =\", aggregated[:,3].std())\n",
        "    return all_results\n",
        "\n",
        "params1 = {'units': 239, 'learning_rate': 0.0016, 'dropout_rate': 0.364, 'num_hidden_layers': 1, 'batch_size': 110, 'epochs': 46, 'l2_reg': 0.0039, 'activation': \"selu\", 'optimizer': \"sgd\"}\n",
        "params2 = {'units': 167, 'learning_rate': 0.0054, 'dropout_rate': 0.3488, 'num_hidden_layers': 1, 'batch_size': 21, 'epochs': 50, 'l2_reg': 0.00612, 'activation': 'selu', 'optimizer': 'rmsprop'}\n",
        "params3 = {'units': 86, 'learning_rate': 0.01, 'dropout_rate': 0.2, 'num_hidden_layers': 3, 'batch_size': 71, 'epochs': 86, 'l2_reg': 0.000001, 'activation': \"selu\", 'optimizer': \"rmsprop\"}\n",
        "params4 = {'units': 150, 'learning_rate': 0.01, 'dropout_rate': 0.5, 'num_hidden_layers': 1, 'batch_size': 84, 'epochs': 88, 'l2_reg': 0.01, 'activation': \"selu\", 'optimizer': \"sgd\"}\n",
        "\n",
        "train = pd.read_csv('df_cluster.csv')\n",
        "test = pd.read_csv('df_cluster_VAL.csv')\n",
        "\n",
        "train = labelize(train)\n",
        "test = labelize(test)\n",
        "test.columns = train.columns # some column names have slighlty different names\n",
        "\n",
        "CORR_THRESHOLD = 0.9\n",
        "\n",
        "X_train = train.drop(columns=['IUIS', 'IUIS extended', 'PCODE','y'])\n",
        "y_train = train['y']\n",
        "X_test = test.drop(columns=['IUIS', 'IUIS extended', 'PCODE','y'])\n",
        "y_test = test['y']\n",
        "\n",
        "run_multiple_cvs(X_train, y_train, n_runs=5, n_splits=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing on the holdout set\n",
        "\n",
        "Before continuing, make sure the optimized preprocessing pipeline and the *create_model* function from the \"Optimized\" section are loaded."
      ],
      "metadata": {
        "id": "OO5FJXui_-Yq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_cascade_TEST(X_train, y_train, X_holdout, y_holdout):\n",
        "\n",
        "    def train_stage(X_tr, X_val, X_te, y_tr, y_val, y_te, stage_num, params, is_binary,\n",
        "                   stage_name, class_names, run_name):\n",
        "\n",
        "        cw = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_val), y=y_val)\n",
        "        cw_dict = {int(cls): float(w) for cls, w in zip(np.unique(y_val), cw)}\n",
        "\n",
        "        model = create_model(X_tr.shape[1], stage_num, params, is_binary=is_binary)\n",
        "        history = model.fit(X_tr, y_tr.values if hasattr(y_tr, 'values') else y_tr,\n",
        "                          validation_data=(X_val, y_val.values),\n",
        "                          epochs=params[\"epochs\"],\n",
        "                          batch_size=params[\"batch_size\"],\n",
        "                          callbacks=callbacks,\n",
        "                          verbose=0,\n",
        "                          class_weight=cw_dict)\n",
        "        plot_history(history)\n",
        "\n",
        "        if is_binary:\n",
        "            p_val = model.predict(X_val, verbose=0).ravel()\n",
        "            thresh = max(find_optimal_threshold(y_val, p_val), 0.2 if stage_num == 2 else 0)\n",
        "            print(f\"Optimal threshold ({stage_name}): {thresh:.3f}\")\n",
        "\n",
        "            p_te = model.predict(X_te, verbose=0).ravel()\n",
        "            pred_te = (p_te >= thresh).astype(int)\n",
        "        else:\n",
        "            thresh = None\n",
        "            p_te = model.predict(X_te, verbose=0)\n",
        "            pred_te = np.argmax(p_te, axis=1)\n",
        "\n",
        "        print(classification_report(y_te, pred_te, digits=4, zero_division=0))\n",
        "        acc = balanced_accuracy_score(y_te, pred_te)\n",
        "        print(\"Balanced Accuracy:\", acc)\n",
        "        cm = confusion_matrix(y_te, pred_te)\n",
        "        plot_confusion_matrix_relative(cm, class_names=class_names,\n",
        "                                      title=f\"{stage_name} - {run_name}\")\n",
        "\n",
        "        return model, thresh, acc\n",
        "\n",
        "    def train_and_evaluate_single_run(X_val_raw, X_test_raw, y_val, y_test, run_name):\n",
        "\n",
        "        # Feature filter and preprocessing\n",
        "        ff = FeatureFilter(corr_threshold=CORR_THRESHOLD)\n",
        "        ff.fit(X_train)\n",
        "        X_tr_ff, X_val_ff, X_te_ff = [ff.transform(X) for X in [X_train, X_val_raw, X_test_raw]]\n",
        "\n",
        "        preprocessors = [build_preprocessor(X_tr_ff, i) for i in [1, 2, 3]]\n",
        "        X_stages = {\n",
        "            'tr': [p.transform(X_tr_ff) for p in preprocessors],\n",
        "            'val': [p.transform(X_val_ff) for p in preprocessors],\n",
        "            'te': [p.transform(X_te_ff) for p in preprocessors]\n",
        "        }\n",
        "\n",
        "        stage_accs = []\n",
        "        stage_preds = {}\n",
        "\n",
        "        # Stage 1: I vs Rest\n",
        "        print(\"\\n-- Stage 1 (I vs Rest) --\")\n",
        "        y1_tr, y1_val, y1_te = [build_stage1_labels(y) for y in [y_train, y_val, y_test]]\n",
        "        m1, thresh1, acc1 = train_stage(\n",
        "            X_stages['tr'][0], X_stages['val'][0], X_stages['te'][0],\n",
        "            y1_tr, y1_val, y1_te, 1, params1, True,\n",
        "            \"Stage 1 (I vs Rest)\", [\"Rest\", \"I\"], run_name\n",
        "        )\n",
        "        stage_accs.append(acc1)\n",
        "        p1_te = m1.predict(X_stages['te'][0], verbose=0).ravel()\n",
        "        stage_preds['stage1'] = {'y_true': y1_te, 'y_pred': (p1_te >= thresh1).astype(int)}\n",
        "\n",
        "        # Stage 2: DC vs Rest\n",
        "        print(\"\\n-- Stage 2 (DC vs Rest) --\")\n",
        "        masks_y2 = [build_stage2_labels(y) for y in [y_train, y_val, y_test]]\n",
        "        X2_masked = [X_stages[k][1][masks_y2[i][0].values] for i, k in enumerate(['tr', 'val', 'te'])]\n",
        "        y2_masked = [masks_y2[i][1] for i in range(3)]\n",
        "\n",
        "        m2, thresh2, acc2 = train_stage(\n",
        "            X2_masked[0], X2_masked[1], X2_masked[2],\n",
        "            y2_masked[0], y2_masked[1], y2_masked[2], 2, params2, True,\n",
        "            \"Stage 2 (DC vs Rest)\", [\"PID\", \"DC\"], run_name\n",
        "        )\n",
        "        stage_accs.append(acc2)\n",
        "        p2_te = m2.predict(X2_masked[2], verbose=0).ravel()\n",
        "        stage_preds['stage2'] = {'y_true': y2_masked[2], 'y_pred': (p2_te >= thresh2).astype(int)}\n",
        "\n",
        "        # Stage 3: Multiclass\n",
        "        print(\"\\n-- Stage 3 (Multiclass) --\")\n",
        "        masks_y3 = [build_stage3_labels(y) for y in [y_train, y_val, y_test]]\n",
        "        X3_masked = [X_stages[k][2][masks_y3[i][0].values] for i, k in enumerate(['tr', 'val', 'te'])]\n",
        "        y3_masked = [masks_y3[i][1] for i in range(3)]\n",
        "\n",
        "        m3, _, acc3 = train_stage(\n",
        "            X3_masked[0], X3_masked[1], X3_masked[2],\n",
        "            y3_masked[0], y3_masked[1], y3_masked[2], 3, params3, False,\n",
        "            \"Stage 3 (Multiclass)\", STAGE3_CLASSES, run_name\n",
        "        )\n",
        "        stage_accs.append(acc3)\n",
        "        p3_te = m3.predict(X3_masked[2], verbose=0)\n",
        "        stage_preds['stage3'] = {'y_true': y3_masked[2].values, 'y_pred': np.argmax(p3_te, axis=1)}\n",
        "\n",
        "        # Overall predictions\n",
        "        pI_all = m1.predict(X_stages['te'][0], verbose=0).ravel()\n",
        "        pDC_all = m2.predict(X_stages['te'][1], verbose=0).ravel()\n",
        "        pS3_all = m3.predict(X_stages['te'][2], verbose=0)\n",
        "\n",
        "        final_probs = soft_gated_combine_probs(pI_all, pDC_all, pS3_all, thresh1, thresh2)\n",
        "        final_preds = [ALL_CLASSES[i] for i in np.argmax(final_probs, axis=1)]\n",
        "\n",
        "        print(f\"\\n== Soft-Gated Overall (Test Set) - {run_name} ==\")\n",
        "        print(classification_report(y_test, final_preds, labels=ALL_CLASSES,\n",
        "                                   target_names=ALL_CLASSES, digits=4, zero_division=0))\n",
        "        acc_final = balanced_accuracy_score(y_test, final_preds)\n",
        "        print(\"Balanced Accuracy:\", acc_final)\n",
        "        cm_final = confusion_matrix(y_test, final_preds, labels=ALL_CLASSES)\n",
        "        plot_confusion_matrix_relative(cm_final, class_names=ALL_CLASSES,\n",
        "                                      title=f\"Final Soft-Gated - {run_name}\")\n",
        "        stage_accs.append(acc_final)\n",
        "\n",
        "        return final_preds, stage_accs, stage_preds\n",
        "\n",
        "    # Split holdout set\n",
        "    sks = StratifiedKFold(n_splits=2, shuffle=True, random_state=RANDOM_STATE)\n",
        "    idx_A, idx_B = next(sks.split(X_holdout, y_holdout))\n",
        "    X_A, X_B = X_holdout.iloc[idx_A].copy(), X_holdout.iloc[idx_B].copy()\n",
        "    y_A, y_B = y_holdout.iloc[idx_A].copy(), y_holdout.iloc[idx_B].copy()\n",
        "\n",
        "    # Storage for aggregated results\n",
        "    all_predictions = {}\n",
        "    all_y_true = {}\n",
        "    all_stage_accuracies = []\n",
        "    all_stage_predictions = {'stage1': [], 'stage2': [], 'stage3': []}\n",
        "\n",
        "    # Run 1: A=validation, B=test\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"RUN 1: Using Split A for validation, Split B for testing\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    preds_run1, accs_run1, stage_preds_run1 = train_and_evaluate_single_run(X_A, X_B, y_A, y_B, \"Run 1\")\n",
        "    for i, idx in enumerate(idx_B):\n",
        "        all_predictions[idx] = preds_run1[i]\n",
        "        all_y_true[idx] = y_B.iloc[i]\n",
        "    all_stage_accuracies.append(accs_run1)\n",
        "    for stage in ['stage1', 'stage2', 'stage3']:\n",
        "        all_stage_predictions[stage].append(stage_preds_run1[stage])\n",
        "\n",
        "    # Run 2: B=validation, A=test (SWAP)\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"RUN 2: Using Split B for validation, Split A for testing (SWAP)\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    preds_run2, accs_run2, stage_preds_run2 = train_and_evaluate_single_run(X_B, X_A, y_B, y_A, \"Run 2\")\n",
        "    for i, idx in enumerate(idx_A):\n",
        "        all_predictions[idx] = preds_run2[i]\n",
        "        all_y_true[idx] = y_A.iloc[i]\n",
        "    all_stage_accuracies.append(accs_run2)\n",
        "    for stage in ['stage1', 'stage2', 'stage3']:\n",
        "        all_stage_predictions[stage].append(stage_preds_run2[stage])\n",
        "\n",
        "    # Aggregated results\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"AGGREGATED RESULTS ACROSS ENTIRE HOLDOUT SET\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Stage 1 aggregated results\n",
        "    print(\"\\n\" + \"-\"*60)\n",
        "    print(\"STAGE 1 (I vs Rest) - AGGREGATED\")\n",
        "    print(\"-\"*60)\n",
        "    y1_true_all = np.concatenate([all_stage_predictions['stage1'][0]['y_true'],\n",
        "                                   all_stage_predictions['stage1'][1]['y_true']])\n",
        "    y1_pred_all = np.concatenate([all_stage_predictions['stage1'][0]['y_pred'],\n",
        "                                   all_stage_predictions['stage1'][1]['y_pred']])\n",
        "    print(classification_report(y1_true_all, y1_pred_all, digits=4, zero_division=0))\n",
        "    bal_acc_stage1 = balanced_accuracy_score(y1_true_all, y1_pred_all)\n",
        "    print(f\"Balanced Accuracy: {bal_acc_stage1:.4f}\")\n",
        "    cm_stage1_agg = confusion_matrix(y1_true_all, y1_pred_all)\n",
        "    plot_confusion_matrix_relative(cm_stage1_agg, class_names=[\"Rest\", \"I\"],\n",
        "                                   title=\"Stage 1 (I vs Rest) - Aggregated\")\n",
        "\n",
        "    # Stage 2 aggregated results\n",
        "    print(\"\\n\" + \"-\"*60)\n",
        "    print(\"STAGE 2 (DC vs Rest) - AGGREGATED\")\n",
        "    print(\"-\"*60)\n",
        "    y2_true_all = np.concatenate([all_stage_predictions['stage2'][0]['y_true'],\n",
        "                                   all_stage_predictions['stage2'][1]['y_true']])\n",
        "    y2_pred_all = np.concatenate([all_stage_predictions['stage2'][0]['y_pred'],\n",
        "                                   all_stage_predictions['stage2'][1]['y_pred']])\n",
        "    print(classification_report(y2_true_all, y2_pred_all, digits=4, zero_division=0))\n",
        "    bal_acc_stage2 = balanced_accuracy_score(y2_true_all, y2_pred_all)\n",
        "    print(f\"Balanced Accuracy: {bal_acc_stage2:.4f}\")\n",
        "    cm_stage2_agg = confusion_matrix(y2_true_all, y2_pred_all)\n",
        "    plot_confusion_matrix_relative(cm_stage2_agg, class_names=[\"PID\", \"DC\"],\n",
        "                                   title=\"Stage 2 (DC vs Rest) - Aggregated\")\n",
        "\n",
        "    # Stage 3 aggregated results\n",
        "    print(\"\\n\" + \"-\"*60)\n",
        "    print(\"STAGE 3 (Multiclass) - AGGREGATED\")\n",
        "    print(\"-\"*60)\n",
        "    y3_true_all = np.concatenate([all_stage_predictions['stage3'][0]['y_true'],\n",
        "                                   all_stage_predictions['stage3'][1]['y_true']])\n",
        "    y3_pred_all = np.concatenate([all_stage_predictions['stage3'][0]['y_pred'],\n",
        "                                   all_stage_predictions['stage3'][1]['y_pred']])\n",
        "    print(classification_report(y3_true_all, y3_pred_all, digits=4, zero_division=0))\n",
        "    bal_acc_stage3 = balanced_accuracy_score(y3_true_all, y3_pred_all)\n",
        "    print(f\"Balanced Accuracy: {bal_acc_stage3:.4f}\")\n",
        "    cm_stage3_agg = confusion_matrix(y3_true_all, y3_pred_all)\n",
        "    plot_confusion_matrix_relative(cm_stage3_agg, class_names=STAGE3_CLASSES,\n",
        "                                   title=\"Stage 3 (Multiclass) - Aggregated\")\n",
        "\n",
        "    # Final soft-gated aggregated results\n",
        "    print(\"\\n\" + \"-\"*60)\n",
        "    print(\"SOFT-GATED OVERALL - AGGREGATED\")\n",
        "    print(\"-\"*60)\n",
        "\n",
        "    sorted_indices = sorted(all_predictions.keys())\n",
        "    final_preds_all = [all_predictions[i] for i in sorted_indices]\n",
        "    y_true_all = [all_y_true[i] for i in sorted_indices]\n",
        "\n",
        "    print(\"\\n== Aggregated Classification Report ==\")\n",
        "    print(classification_report(y_true_all, final_preds_all, labels=ALL_CLASSES,\n",
        "                               target_names=ALL_CLASSES, digits=4, zero_division=0))\n",
        "\n",
        "    bal_acc_aggregated = balanced_accuracy_score(y_true_all, final_preds_all)\n",
        "    print(f\"\\nAggregated Balanced Accuracy: {bal_acc_aggregated:.4f}\")\n",
        "\n",
        "    cm_aggregated = confusion_matrix(y_true_all, final_preds_all, labels=ALL_CLASSES)\n",
        "    plot_confusion_matrix_relative(cm_aggregated, class_names=ALL_CLASSES,\n",
        "                                  title=\"Aggregated Final Confusion Matrix (Entire Holdout)\")\n",
        "\n",
        "    avg_stage_accs = np.mean(all_stage_accuracies, axis=0)\n",
        "    print(f\"\\n== Average Stage Balanced Accuracies ==\")\n",
        "    print(f\"Stage 1 (I vs Rest): {avg_stage_accs[0]:.4f}\")\n",
        "    print(f\"Stage 2 (DC vs Rest): {avg_stage_accs[1]:.4f}\")\n",
        "    print(f\"Stage 3 (Multiclass): {avg_stage_accs[2]:.4f}\")\n",
        "    print(f\"Final (Soft-Gated): {avg_stage_accs[3]:.4f}\")\n",
        "\n",
        "    return final_preds_all, [bal_acc_stage1, bal_acc_stage2, bal_acc_stage3, bal_acc_aggregated]"
      ],
      "metadata": {
        "id": "Y9K2JbSpwxRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params1 = {'units': 239, 'learning_rate': 0.0016, 'dropout_rate': 0.364, 'num_hidden_layers': 1, 'batch_size': 110, 'epochs': 46, 'l2_reg': 0.0039, 'activation': \"selu\", 'optimizer': \"sgd\"}\n",
        "params2 = {'units': 167, 'learning_rate': 0.0054, 'dropout_rate': 0.3488, 'num_hidden_layers': 1, 'batch_size': 21, 'epochs': 50, 'l2_reg': 0.00612, 'activation': 'selu', 'optimizer': 'rmsprop'}\n",
        "params3 = {'units': 86, 'learning_rate': 0.01, 'dropout_rate': 0.2, 'num_hidden_layers': 3, 'batch_size': 71, 'epochs': 86, 'l2_reg': 0.000001, 'activation': \"selu\", 'optimizer': \"rmsprop\"}\n",
        "params4 = {'units': 150, 'learning_rate': 0.01, 'dropout_rate': 0.5, 'num_hidden_layers': 1, 'batch_size': 84, 'epochs': 88, 'l2_reg': 0.01, 'activation': \"selu\", 'optimizer': \"sgd\"}\n",
        "\n",
        "train = pd.read_csv('df_cluster.csv')\n",
        "test = pd.read_csv('df_cluster_VAL.csv')\n",
        "\n",
        "train = labelize(train)\n",
        "test = labelize(test)\n",
        "test.columns = train.columns # some column names have slighlty different names\n",
        "\n",
        "CORR_THRESHOLD = 0.9\n",
        "\n",
        "X_train = train.drop(columns=['IUIS', 'IUIS extended', 'PCODE','y'])\n",
        "y_train = train['y']\n",
        "X_test = test.drop(columns=['IUIS', 'IUIS extended', 'PCODE','y'])\n",
        "y_test = test['y']\n",
        "\n",
        "accs = []\n",
        "for i in range(20):\n",
        "    report, b_acc = run_cascade_TEST(X_train, y_train, X_test, y_test)\n",
        "    accs.append(b_acc)\n",
        "print(accs)"
      ],
      "metadata": {
        "id": "zSpURF8WBG-q",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=8,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.3,\n",
        "    patience=3,\n",
        "    min_lr=1e-7\n",
        ")\n",
        "\n",
        "callbacks = [early_stop, reduce_lr]\n",
        "\n",
        "def run_multi_TEST(X_train, y_train, X_holdout, y_holdout, params):\n",
        "    \"\"\"\n",
        "    Train multiclass model on training set, swap validation/test splits to predict entire holdout.\n",
        "    Returns predictions for entire holdout set and aggregated metrics.\n",
        "    \"\"\"\n",
        "\n",
        "    def train_and_evaluate_single_run(X_val, X_test, y_val, y_test, run_name):\n",
        "        \"\"\"Helper function to train and evaluate one run\"\"\"\n",
        "\n",
        "        # Encode labels\n",
        "        le = LabelEncoder()\n",
        "        y_train_enc, y_val_enc, y_test_enc = [le.fit_transform(y_train) if i == 0 else le.transform(y)\n",
        "                                               for i, y in enumerate([y_train, y_val, y_test])]\n",
        "        class_names = le.classes_\n",
        "\n",
        "        # Feature filter and preprocessing\n",
        "        ff = FeatureFilter(corr_threshold=CORR_THRESHOLD)\n",
        "        ff.fit(X_train)\n",
        "        X_tr_ff, X_val_ff, X_te_ff = [ff.transform(X) for X in [X_train, X_val, X_test]]\n",
        "\n",
        "        pre_multi = build_preprocessor_multi(X_tr_ff)\n",
        "        X_tr_prep, X_val_prep, X_te_prep = [pre_multi.transform(X) for X in [X_tr_ff, X_val_ff, X_te_ff]]\n",
        "        input_dim = X_tr_prep.shape[1]\n",
        "\n",
        "        # Class weights\n",
        "        cw = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_train_enc), y=y_train_enc)\n",
        "        cw_dict = {cls: w for cls, w in zip(np.unique(y_train_enc), cw)}\n",
        "\n",
        "        # Build and train model\n",
        "        model = create_model(input_dim, 4, params, is_binary=False)\n",
        "        history = model.fit(\n",
        "            X_tr_prep, y_train_enc,\n",
        "            validation_data=(X_val_prep, y_val_enc),\n",
        "            epochs=int(params[\"epochs\"]),\n",
        "            batch_size=int(params[\"batch_size\"]),\n",
        "            callbacks=callbacks,\n",
        "            verbose=0,\n",
        "            class_weight=cw_dict\n",
        "        )\n",
        "\n",
        "        # Predictions\n",
        "        y_pred_prob = model.predict(X_te_prep, verbose=1)\n",
        "        y_pred_idx = np.argmax(y_pred_prob, axis=1)\n",
        "        y_test_labels = le.inverse_transform(y_test_enc)\n",
        "        y_pred_labels = le.inverse_transform(y_pred_idx)\n",
        "\n",
        "        # Reports\n",
        "        print(f\"\\n== Test Set Evaluation - {run_name} ==\")\n",
        "        print(classification_report(y_test_labels, y_pred_labels, labels=class_names, digits=4, zero_division=0))\n",
        "        bal_acc = balanced_accuracy_score(y_test_labels, y_pred_labels)\n",
        "        print(\"Balanced Accuracy:\", bal_acc)\n",
        "        cm = confusion_matrix(y_test_labels, y_pred_labels, labels=class_names)\n",
        "        print(\"Confusion Matrix:\\n\", cm)\n",
        "        plot_confusion_matrix_relative(cm, class_names=class_names, title=f\"Test Confusion Matrix - {run_name}\")\n",
        "\n",
        "        return y_test_labels, y_pred_labels, bal_acc, class_names, history\n",
        "\n",
        "    # Split holdout set\n",
        "    sks = StratifiedKFold(n_splits=2, shuffle=True, random_state=RANDOM_STATE)\n",
        "    idx_A, idx_B = next(sks.split(X_holdout, y_holdout))\n",
        "    X_A, X_B = X_holdout.iloc[idx_A].copy(), X_holdout.iloc[idx_B].copy()\n",
        "    y_A, y_B = y_holdout.iloc[idx_A].copy(), y_holdout.iloc[idx_B].copy()\n",
        "\n",
        "    # Storage for aggregated results\n",
        "    all_predictions = {}\n",
        "    all_y_true = {}\n",
        "    all_balanced_accs = []\n",
        "\n",
        "    # Run 1: A=validation, B=test\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"RUN 1: Using Split A for validation, Split B for testing\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    y_test_1, y_pred_1, bal_acc_1, class_names, history = train_and_evaluate_single_run(X_A, X_B, y_A, y_B, \"Run 1\")\n",
        "    for i, idx in enumerate(idx_B):\n",
        "        all_predictions[idx] = y_pred_1[i]\n",
        "        all_y_true[idx] = y_test_1[i]\n",
        "    all_balanced_accs.append(bal_acc_1)\n",
        "\n",
        "    # Run 2: B=validation, A=test (SWAP)\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"RUN 2: Using Split B for validation, Split A for testing (SWAP)\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    y_test_2, y_pred_2, bal_acc_2, _, history = train_and_evaluate_single_run(X_B, X_A, y_B, y_A, \"Run 2\")\n",
        "    for i, idx in enumerate(idx_A):\n",
        "        all_predictions[idx] = y_pred_2[i]\n",
        "        all_y_true[idx] = y_test_2[i]\n",
        "    all_balanced_accs.append(bal_acc_2)\n",
        "\n",
        "    # Aggregated results\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"AGGREGATED RESULTS ACROSS ENTIRE HOLDOUT SET\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    sorted_indices = sorted(all_predictions.keys())\n",
        "    final_preds_all = [all_predictions[i] for i in sorted_indices]\n",
        "    y_true_all = [all_y_true[i] for i in sorted_indices]\n",
        "\n",
        "    print(\"\\n== Aggregated Classification Report ==\")\n",
        "    print(classification_report(y_true_all, final_preds_all, labels=class_names, digits=4, zero_division=0))\n",
        "\n",
        "    bal_acc_aggregated = balanced_accuracy_score(y_true_all, final_preds_all)\n",
        "    print(f\"\\nAggregated Balanced Accuracy: {bal_acc_aggregated:.4f}\")\n",
        "\n",
        "    cm_aggregated = confusion_matrix(y_true_all, final_preds_all, labels=class_names)\n",
        "    print(\"Aggregated Confusion Matrix:\\n\", cm_aggregated)\n",
        "    plot_confusion_matrix_relative(cm_aggregated, class_names=class_names,\n",
        "                                   title=\"Aggregated Confusion Matrix (Entire Holdout)\")\n",
        "\n",
        "    avg_bal_acc = np.mean(all_balanced_accs)\n",
        "    print(f\"\\n== Average Balanced Accuracy Across Runs ==\")\n",
        "    print(f\"Run 1: {all_balanced_accs[0]:.4f}\")\n",
        "    print(f\"Run 2: {all_balanced_accs[1]:.4f}\")\n",
        "    print(f\"Average: {avg_bal_acc:.4f}\")\n",
        "\n",
        "    return (\n",
        "        {\"y_true\": pd.Series(y_true_all).reset_index(drop=True),\n",
        "         \"y_pred\": pd.Series(final_preds_all).reset_index(drop=True)},\n",
        "        bal_acc_aggregated,\n",
        "        history\n",
        "    )"
      ],
      "metadata": {
        "id": "MQ4fp6AOptpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params4 = {'units': 150, 'learning_rate': 0.01, 'dropout_rate': 0.5, 'num_hidden_layers': 1, 'batch_size': 84, 'epochs': 88, 'l2_reg': 0.01, 'activation': \"selu\", 'optimizer': \"sgd\"}\n",
        "\n",
        "train = pd.read_csv('df_cluster.csv')\n",
        "test = pd.read_csv('df_cluster_VAL.csv')\n",
        "train = labelize(train)\n",
        "test = labelize(test)\n",
        "test.columns = train.columns # some column names have slighlty different names\n",
        "\n",
        "X_train = train.drop(columns=['IUIS', 'IUIS extended', 'PCODE','y'])\n",
        "y_train = train['y']\n",
        "X_holdout = test.drop(columns=['IUIS', 'IUIS extended', 'PCODE','y'])\n",
        "y_holdout =  test['y']\n",
        "\n",
        "accs = []\n",
        "for i in range(10):\n",
        "    report, b_acc, history = run_multi_TEST(X_train, y_train, X_holdout, y_holdout, params4)\n",
        "    accs.append(b_acc)\n",
        "accs = [float(a) for a in accs]\n",
        "print(accs)\n",
        "print(statistics.mean(accs), statistics.pstdev(accs) / math.sqrt(len(accs)))"
      ],
      "metadata": {
        "id": "dM1dHiyoJ9nu",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQFyFIAHh8is"
      },
      "source": [
        "# Testing with balanced batching\n",
        "\n",
        "Before continuing, make sure the optimized preprocessing pipeline and the *create_model* function from the \"Optimized\" section are loaded."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BalancedBatchGenerator(Sequence):\n",
        "    \"\"\"\n",
        "    Generates balanced batches from (X, y) for imbalanced classification problems.\n",
        "    Each batch includes approximately equal samples from each class.\n",
        "    \"\"\"\n",
        "    def __init__(self, X, y, batch_size=32, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.X = np.asarray(X)\n",
        "        self.y = np.asarray(y)\n",
        "        self.batch_size = batch_size\n",
        "        self.classes, self.class_indices = np.unique(self.y, return_inverse=True)\n",
        "        self.indices_per_class = {cls: np.where(self.y == cls)[0] for cls in self.classes}\n",
        "        self.samples_per_class = max(1, batch_size // len(self.classes))\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.y) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_indices = []\n",
        "        for cls in self.classes:\n",
        "            cls_indices = np.random.choice(\n",
        "                self.indices_per_class[cls],\n",
        "                size=self.samples_per_class,\n",
        "                replace=len(self.indices_per_class[cls]) < self.samples_per_class\n",
        "            )\n",
        "            batch_indices.extend(cls_indices)\n",
        "        np.random.shuffle(batch_indices)\n",
        "        X_batch = self.X[batch_indices]\n",
        "        y_batch = self.y[batch_indices]\n",
        "        return X_batch, y_batch"
      ],
      "metadata": {
        "id": "HAkd2nCZPHGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_cascade_TEST(X_train, y_train, X_holdout, y_holdout):\n",
        "    \"\"\"\n",
        "    Train cascade on training set, swap validation/test splits to predict entire holdout.\n",
        "    Returns predictions for entire holdout set and aggregated metrics.\n",
        "    \"\"\"\n",
        "\n",
        "    def train_stage(X_tr, X_val, X_te, y_tr, y_val, y_te, stage_num, params, is_binary,\n",
        "                   stage_name, class_names, run_name):\n",
        "        \"\"\"Helper to train and evaluate one stage\"\"\"\n",
        "        gen = BalancedBatchGenerator(X_tr, y_tr.values if hasattr(y_tr, 'values') else y_tr,\n",
        "                                     batch_size=params[\"batch_size\"])\n",
        "\n",
        "        model = create_model(X_tr.shape[1], stage_num, params, is_binary=is_binary)\n",
        "        history = model.fit(gen,\n",
        "                          validation_data=(X_val, y_val.values),\n",
        "                          epochs=params[\"epochs\"],\n",
        "                          callbacks=callbacks,\n",
        "                          verbose=0)\n",
        "        plot_history(history)\n",
        "\n",
        "        if is_binary:\n",
        "            p_val = model.predict(X_val, verbose=0).ravel()\n",
        "            thresh = max(find_optimal_threshold(y_val, p_val), 0.2 if stage_num == 2 else 0)\n",
        "            print(f\"Optimal threshold ({stage_name}): {thresh:.3f}\")\n",
        "\n",
        "            p_te = model.predict(X_te, verbose=0).ravel()\n",
        "            pred_te = (p_te >= thresh).astype(int)\n",
        "        else:\n",
        "            thresh = None\n",
        "            p_te = model.predict(X_te, verbose=0)\n",
        "            pred_te = np.argmax(p_te, axis=1)\n",
        "\n",
        "        print(classification_report(y_te, pred_te, digits=4, zero_division=0))\n",
        "        acc = balanced_accuracy_score(y_te, pred_te)\n",
        "        print(\"Balanced Accuracy:\", acc)\n",
        "        cm = confusion_matrix(y_te, pred_te)\n",
        "        plot_confusion_matrix_relative(cm, class_names=class_names,\n",
        "                                      title=f\"{stage_name} - {run_name}\")\n",
        "\n",
        "        return model, thresh, acc\n",
        "\n",
        "    def train_and_evaluate_single_run(X_val_raw, X_test_raw, y_val, y_test, run_name):\n",
        "        \"\"\"Helper function to train and evaluate one cascade run\"\"\"\n",
        "\n",
        "        # Feature filter and preprocessing\n",
        "        ff = FeatureFilter(corr_threshold=CORR_THRESHOLD)\n",
        "        ff.fit(X_train)\n",
        "        X_tr_ff, X_val_ff, X_te_ff = [ff.transform(X) for X in [X_train, X_val_raw, X_test_raw]]\n",
        "\n",
        "        preprocessors = [build_preprocessor(X_tr_ff, i) for i in [1, 2, 3]]\n",
        "        X_stages = {\n",
        "            'tr': [p.transform(X_tr_ff) for p in preprocessors],\n",
        "            'val': [p.transform(X_val_ff) for p in preprocessors],\n",
        "            'te': [p.transform(X_te_ff) for p in preprocessors]\n",
        "        }\n",
        "\n",
        "        stage_accs = []\n",
        "\n",
        "        # Stage 1: I vs Rest\n",
        "        print(\"\\n-- Stage 1 (I vs Rest) --\")\n",
        "        y1_tr, y1_val, y1_te = [build_stage1_labels(y) for y in [y_train, y_val, y_test]]\n",
        "        m1, thresh1, acc1 = train_stage(\n",
        "            X_stages['tr'][0], X_stages['val'][0], X_stages['te'][0],\n",
        "            y1_tr, y1_val, y1_te, 1, params1, True,\n",
        "            \"Stage 1 (I vs Rest)\", [\"Rest\", \"I\"], run_name\n",
        "        )\n",
        "        stage_accs.append(acc1)\n",
        "\n",
        "        # Stage 2: DC vs Rest\n",
        "        print(\"\\n-- Stage 2 (DC vs Rest) --\")\n",
        "        masks_y2 = [build_stage2_labels(y) for y in [y_train, y_val, y_test]]\n",
        "        X2_masked = [X_stages[k][1][masks_y2[i][0].values] for i, k in enumerate(['tr', 'val', 'te'])]\n",
        "        y2_masked = [masks_y2[i][1] for i in range(3)]\n",
        "\n",
        "        m2, thresh2, acc2 = train_stage(\n",
        "            X2_masked[0], X2_masked[1], X2_masked[2],\n",
        "            y2_masked[0], y2_masked[1], y2_masked[2], 2, params2, True,\n",
        "            \"Stage 2 (DC vs Rest)\", [\"PID\", \"DC\"], run_name\n",
        "        )\n",
        "        stage_accs.append(acc2)\n",
        "\n",
        "        # Stage 3: Multiclass\n",
        "        print(\"\\n-- Stage 3 (Multiclass) --\")\n",
        "        masks_y3 = [build_stage3_labels(y) for y in [y_train, y_val, y_test]]\n",
        "        X3_masked = [X_stages[k][2][masks_y3[i][0].values] for i, k in enumerate(['tr', 'val', 'te'])]\n",
        "        y3_masked = [masks_y3[i][1] for i in range(3)]\n",
        "\n",
        "        m3, _, acc3 = train_stage(\n",
        "            X3_masked[0], X3_masked[1], X3_masked[2],\n",
        "            y3_masked[0], y3_masked[1], y3_masked[2], 3, params3, False,\n",
        "            \"Stage 3 (Multiclass)\", STAGE3_CLASSES, run_name\n",
        "        )\n",
        "        stage_accs.append(acc3)\n",
        "\n",
        "        # Overall predictions\n",
        "        pI_all = m1.predict(X_stages['te'][0], verbose=0).ravel()\n",
        "        pDC_all = m2.predict(X_stages['te'][1], verbose=0).ravel()\n",
        "        pS3_all = m3.predict(X_stages['te'][2], verbose=0)\n",
        "\n",
        "        final_probs = soft_gated_combine_probs(pI_all, pDC_all, pS3_all, thresh1, thresh2)\n",
        "        final_preds = [ALL_CLASSES[i] for i in np.argmax(final_probs, axis=1)]\n",
        "\n",
        "        print(f\"\\n== Soft-Gated Overall (Test Set) - {run_name} ==\")\n",
        "        print(classification_report(y_test, final_preds, labels=ALL_CLASSES,\n",
        "                                   target_names=ALL_CLASSES, digits=4, zero_division=0))\n",
        "        acc_final = balanced_accuracy_score(y_test, final_preds)\n",
        "        print(\"Balanced Accuracy:\", acc_final)\n",
        "        cm_final = confusion_matrix(y_test, final_preds, labels=ALL_CLASSES)\n",
        "        plot_confusion_matrix_relative(cm_final, class_names=ALL_CLASSES,\n",
        "                                      title=f\"Final Soft-Gated - {run_name}\")\n",
        "        stage_accs.append(acc_final)\n",
        "\n",
        "        return final_preds, stage_accs\n",
        "\n",
        "    # Split holdout set\n",
        "    sks = StratifiedKFold(n_splits=2, shuffle=True, random_state=RANDOM_STATE)\n",
        "    idx_A, idx_B = next(sks.split(X_holdout, y_holdout))\n",
        "    X_A, X_B = X_holdout.iloc[idx_A].copy(), X_holdout.iloc[idx_B].copy()\n",
        "    y_A, y_B = y_holdout.iloc[idx_A].copy(), y_holdout.iloc[idx_B].copy()\n",
        "\n",
        "    # Storage for aggregated results\n",
        "    all_predictions = {}\n",
        "    all_y_true = {}\n",
        "    all_stage_accuracies = []\n",
        "\n",
        "    # Run 1: A=validation, B=test\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"RUN 1: Using Split A for validation, Split B for testing\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    preds_run1, accs_run1 = train_and_evaluate_single_run(X_A, X_B, y_A, y_B, \"Run 1\")\n",
        "    for i, idx in enumerate(idx_B):\n",
        "        all_predictions[idx] = preds_run1[i]\n",
        "        all_y_true[idx] = y_B.iloc[i]\n",
        "    all_stage_accuracies.append(accs_run1)\n",
        "\n",
        "    # Run 2: B=validation, A=test (SWAP)\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"RUN 2: Using Split B for validation, Split A for testing (SWAP)\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    preds_run2, accs_run2 = train_and_evaluate_single_run(X_B, X_A, y_B, y_A, \"Run 2\")\n",
        "    for i, idx in enumerate(idx_A):\n",
        "        all_predictions[idx] = preds_run2[i]\n",
        "        all_y_true[idx] = y_A.iloc[i]\n",
        "    all_stage_accuracies.append(accs_run2)\n",
        "\n",
        "    # Aggregated results\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"AGGREGATED RESULTS ACROSS ENTIRE HOLDOUT SET\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    sorted_indices = sorted(all_predictions.keys())\n",
        "    final_preds_all = [all_predictions[i] for i in sorted_indices]\n",
        "    y_true_all = [all_y_true[i] for i in sorted_indices]\n",
        "\n",
        "    print(\"\\n== Aggregated Classification Report ==\")\n",
        "    print(classification_report(y_true_all, final_preds_all, labels=ALL_CLASSES,\n",
        "                               target_names=ALL_CLASSES, digits=4, zero_division=0))\n",
        "\n",
        "    bal_acc_aggregated = balanced_accuracy_score(y_true_all, final_preds_all)\n",
        "    print(f\"\\nAggregated Balanced Accuracy: {bal_acc_aggregated:.4f}\")\n",
        "\n",
        "    cm_aggregated = confusion_matrix(y_true_all, final_preds_all, labels=ALL_CLASSES)\n",
        "    plot_confusion_matrix_relative(cm_aggregated, class_names=ALL_CLASSES,\n",
        "                                  title=\"Aggregated Final Confusion Matrix (Entire Holdout)\")\n",
        "\n",
        "    avg_stage_accs = np.mean(all_stage_accuracies, axis=0)\n",
        "    print(f\"\\n== Average Stage Balanced Accuracies ==\")\n",
        "    print(f\"Stage 1 (I vs Rest): {avg_stage_accs[0]:.4f}\")\n",
        "    print(f\"Stage 2 (DC vs Rest): {avg_stage_accs[1]:.4f}\")\n",
        "    print(f\"Stage 3 (Multiclass): {avg_stage_accs[2]:.4f}\")\n",
        "    print(f\"Final (Soft-Gated): {avg_stage_accs[3]:.4f}\")\n",
        "\n",
        "    return final_preds_all, [avg_stage_accs[0], avg_stage_accs[1], avg_stage_accs[2], bal_acc_aggregated]"
      ],
      "metadata": {
        "id": "YHnznAgbR2GD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cp3NaOWiCIi",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "params1 = {'units': 239, 'learning_rate': 0.0016, 'dropout_rate': 0.364, 'num_hidden_layers': 1, 'batch_size': 110, 'epochs': 46, 'l2_reg': 0.0039, 'activation': \"selu\", 'optimizer': \"sgd\"}\n",
        "#params2 = {'units': 167, 'learning_rate': 0.0054, 'dropout_rate': 0.3488, 'num_hidden_layers': 1, 'batch_size': 21, 'epochs': 50, 'l2_reg': 0.00612, 'activation': 'selu', 'optimizer': 'rmsprop'}\n",
        "params2 = {'units': 236, 'learning_rate': 0.0092, 'dropout_rate': 0.484, 'num_hidden_layers': 1, 'batch_size': 84, 'epochs': 59, 'l2_reg': 0.0018, 'activation': \"selu\", 'optimizer': \"sgd\"}\n",
        "params3 = {'units': 86, 'learning_rate': 0.01, 'dropout_rate': 0.2, 'num_hidden_layers': 3, 'batch_size': 71, 'epochs': 86, 'l2_reg': 0.000001, 'activation': \"selu\", 'optimizer': \"rmsprop\"}\n",
        "params4 = {'units': 150, 'learning_rate': 0.01, 'dropout_rate': 0.5, 'num_hidden_layers': 1, 'batch_size': 84, 'epochs': 88, 'l2_reg': 0.01, 'activation': \"selu\", 'optimizer': \"sgd\"}\n",
        "\n",
        "train = pd.read_csv('df_cluster.csv')\n",
        "test = pd.read_csv('df_cluster_VAL.csv')\n",
        "\n",
        "train = labelize(train)\n",
        "test = labelize(test)\n",
        "test.columns = train.columns # some column names have slighlty different names\n",
        "\n",
        "CORR_THRESHOLD = 0.9\n",
        "\n",
        "X_train = train.drop(columns=['IUIS', 'IUIS extended', 'PCODE','y'])\n",
        "y_train = train['y']\n",
        "X_test = test.drop(columns=['IUIS', 'IUIS extended', 'PCODE','y'])\n",
        "y_test = test['y']\n",
        "\n",
        "accs = []\n",
        "for i in range(10):\n",
        "    report, b_acc = run_cascade_TEST(X_train, y_train, X_test, y_test)\n",
        "    accs.append(b_acc)\n",
        "for element in accs:\n",
        "    element = [float(a) for a in element]\n",
        "    print(element)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_multi_TEST(X_train, y_train, X_holdout, y_holdout, params):\n",
        "\n",
        "    def train_and_evaluate_single_run(X_val, X_test, y_val, y_test, run_name):\n",
        "\n",
        "        # Encode labels\n",
        "        le = LabelEncoder()\n",
        "        y_train_enc = le.fit_transform(y_train)\n",
        "        y_val_enc = le.transform(y_val)\n",
        "        y_test_enc = le.transform(y_test)\n",
        "        class_names = le.classes_\n",
        "\n",
        "        # Feature filter\n",
        "        ff = FeatureFilter(corr_threshold=CORR_THRESHOLD)\n",
        "        ff.fit(X_train)\n",
        "        X_tr_ff, X_val_ff, X_te_ff = [ff.transform(X) for X in [X_train, X_val, X_test]]\n",
        "\n",
        "        # Preprocessing\n",
        "        pre_multi = build_preprocessor_multi(X_tr_ff)\n",
        "        X_tr_prep, X_val_prep, X_te_prep = [pre_multi.transform(X) for X in [X_tr_ff, X_val_ff, X_te_ff]]\n",
        "        input_dim = X_tr_prep.shape[1]\n",
        "\n",
        "        # Build and train model\n",
        "        gen = BalancedBatchGenerator(X_tr_prep, y_train_enc, batch_size=params[\"batch_size\"])\n",
        "        model = create_model(input_dim, 4, params, is_binary=False)\n",
        "        history = model.fit(\n",
        "            gen,\n",
        "            validation_data=(X_val_prep, y_val_enc),\n",
        "            epochs=int(params[\"epochs\"]),\n",
        "            callbacks=callbacks,\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        # Predictions\n",
        "        y_pred_prob = model.predict(X_te_prep, verbose=1)\n",
        "        y_pred_idx = np.argmax(y_pred_prob, axis=1)\n",
        "        y_test_labels = le.inverse_transform(y_test_enc)\n",
        "        y_pred_labels = le.inverse_transform(y_pred_idx)\n",
        "\n",
        "        # Reports\n",
        "        print(f\"\\n== Test Set Evaluation - {run_name} ==\")\n",
        "        print(classification_report(y_test_labels, y_pred_labels, labels=class_names, digits=4, zero_division=0))\n",
        "        bal_acc = balanced_accuracy_score(y_test_labels, y_pred_labels)\n",
        "        print(\"Balanced Accuracy:\", bal_acc)\n",
        "        cm = confusion_matrix(y_test_labels, y_pred_labels, labels=class_names)\n",
        "        print(\"Confusion Matrix:\\n\", cm)\n",
        "        plot_confusion_matrix_relative(cm, class_names=class_names, title=f\"Test Confusion Matrix - {run_name}\")\n",
        "\n",
        "        return y_test_labels, y_pred_labels, bal_acc, class_names, history\n",
        "\n",
        "    # Split holdout set\n",
        "    sks = StratifiedKFold(n_splits=2, shuffle=True, random_state=RANDOM_STATE)\n",
        "    idx_A, idx_B = next(sks.split(X_holdout, y_holdout))\n",
        "    X_A, X_B = X_holdout.iloc[idx_A].copy(), X_holdout.iloc[idx_B].copy()\n",
        "    y_A, y_B = y_holdout.iloc[idx_A].copy(), y_holdout.iloc[idx_B].copy()\n",
        "\n",
        "    # Storage for aggregated results\n",
        "    all_predictions = {}\n",
        "    all_y_true = {}\n",
        "    all_balanced_accs = []\n",
        "\n",
        "    # Run 1: A=validation, B=test\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"RUN 1: Using Split A for validation, Split B for testing\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    y_test_1, y_pred_1, bal_acc_1, class_names, history = train_and_evaluate_single_run(X_A, X_B, y_A, y_B, \"Run 1\")\n",
        "    for i, idx in enumerate(idx_B):\n",
        "        all_predictions[idx] = y_pred_1[i]\n",
        "        all_y_true[idx] = y_test_1[i]\n",
        "    all_balanced_accs.append(bal_acc_1)\n",
        "\n",
        "    # Run 2: B=validation, A=test (SWAP)\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"RUN 2: Using Split B for validation, Split A for testing (SWAP)\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    y_test_2, y_pred_2, bal_acc_2, _, history = train_and_evaluate_single_run(X_B, X_A, y_B, y_A, \"Run 2\")\n",
        "    for i, idx in enumerate(idx_A):\n",
        "        all_predictions[idx] = y_pred_2[i]\n",
        "        all_y_true[idx] = y_test_2[i]\n",
        "    all_balanced_accs.append(bal_acc_2)\n",
        "\n",
        "    # Aggregated results\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"AGGREGATED RESULTS ACROSS ENTIRE HOLDOUT SET\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    sorted_indices = sorted(all_predictions.keys())\n",
        "    final_preds_all = [all_predictions[i] for i in sorted_indices]\n",
        "    y_true_all = [all_y_true[i] for i in sorted_indices]\n",
        "\n",
        "    print(\"\\n== Aggregated Classification Report ==\")\n",
        "    print(classification_report(y_true_all, final_preds_all, labels=class_names, digits=4, zero_division=0))\n",
        "\n",
        "    bal_acc_aggregated = balanced_accuracy_score(y_true_all, final_preds_all)\n",
        "    print(f\"\\nAggregated Balanced Accuracy: {bal_acc_aggregated:.4f}\")\n",
        "\n",
        "    cm_aggregated = confusion_matrix(y_true_all, final_preds_all, labels=class_names)\n",
        "    print(\"Aggregated Confusion Matrix:\\n\", cm_aggregated)\n",
        "    plot_confusion_matrix_relative(cm_aggregated, class_names=class_names,\n",
        "                                   title=\"Aggregated Confusion Matrix (Entire Holdout)\")\n",
        "\n",
        "    avg_bal_acc = np.mean(all_balanced_accs)\n",
        "    print(f\"\\n== Average Balanced Accuracy Across Runs ==\")\n",
        "    print(f\"Run 1: {all_balanced_accs[0]:.4f}\")\n",
        "    print(f\"Run 2: {all_balanced_accs[1]:.4f}\")\n",
        "    print(f\"Average: {avg_bal_acc:.4f}\")\n",
        "\n",
        "    return (\n",
        "        {\"y_true\": pd.Series(y_true_all).reset_index(drop=True),\n",
        "         \"y_pred\": pd.Series(final_preds_all).reset_index(drop=True)},\n",
        "        bal_acc_aggregated,\n",
        "        history\n",
        "    )"
      ],
      "metadata": {
        "id": "QAkRc3k5KB83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params4 = {'units': 150, 'learning_rate': 0.01, 'dropout_rate': 0.5, 'num_hidden_layers': 1, 'batch_size': 84, 'epochs': 88, 'l2_reg': 0.01, 'activation': \"selu\", 'optimizer': \"sgd\"}\n",
        "\n",
        "train = pd.read_csv('df_cluster.csv')\n",
        "test = pd.read_csv('df_cluster_VAL.csv')\n",
        "train = labelize(train)\n",
        "test = labelize(test)\n",
        "test.columns = train.columns # some column names have slighlty different names\n",
        "\n",
        "X_train = train.drop(columns=['IUIS', 'IUIS extended', 'PCODE','y'])\n",
        "y_train = train['y']\n",
        "X_holdout = test.drop(columns=['IUIS', 'IUIS extended', 'PCODE','y'])\n",
        "y_holdout =  test['y']\n",
        "\n",
        "accs = []\n",
        "for i in range(10):\n",
        "    report, b_acc, history = run_multi_TEST(X_train, y_train, X_holdout, y_holdout, params4)\n",
        "    accs.append(b_acc)\n",
        "accs = [float(a) for a in accs]\n",
        "print(accs)\n",
        "print(statistics.mean(accs), statistics.pstdev(accs) / math.sqrt(len(accs)))"
      ],
      "metadata": {
        "id": "foYCmOrRKibU",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AIFpXdpEQ20"
      },
      "source": [
        "# Testing (not aggregated)\n",
        "\n",
        "Before continuing, make sure the optimized preprocessing pipeline and the *create_model* function from the \"Optimized\" section are loaded."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_cascade_TEST(X_train, y_train, X_holdout, y_holdout):\n",
        "    \"\"\"\n",
        "    Train cascade on a training set (with 20% reserved for validation),\n",
        "    and evaluate on the full holdout set.\n",
        "    \"\"\"\n",
        "    accuracies = []\n",
        "\n",
        "    # --- Split training set into train (80%) and validation (20%)\n",
        "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=RANDOM_STATE)\n",
        "    train_idx, val_idx = next(sss.split(X_train, y_train))\n",
        "\n",
        "    X_tr_raw, X_val_raw = X_train.iloc[train_idx].copy(), X_train.iloc[val_idx].copy()\n",
        "    y_tr, y_val = y_train.iloc[train_idx].copy(), y_train.iloc[val_idx].copy()\n",
        "\n",
        "    # Use entire holdout set for testing\n",
        "    X_test_raw = X_holdout.copy()\n",
        "    y_test = y_holdout.copy()\n",
        "\n",
        "    # ---- Feature filter\n",
        "    ff = FeatureFilter(corr_threshold=CORR_THRESHOLD)\n",
        "    ff.fit(X_tr_raw)\n",
        "    X_tr_ff = ff.transform(X_tr_raw)\n",
        "    X_val_ff = ff.transform(X_val_raw)\n",
        "    X_te_ff = ff.transform(X_test_raw)\n",
        "\n",
        "    # ---- Preprocessing\n",
        "    pre1 = build_preprocessor(X_tr_ff, 1)\n",
        "    X1_tr, X1_val, X1_te = (\n",
        "        pre1.transform(X_tr_ff),\n",
        "        pre1.transform(X_val_ff),\n",
        "        pre1.transform(X_te_ff),\n",
        "    )\n",
        "\n",
        "    pre2 = build_preprocessor(X_tr_ff, 2)\n",
        "    X2_tr, X2_val, X2_te = (\n",
        "        pre2.transform(X_tr_ff),\n",
        "        pre2.transform(X_val_ff),\n",
        "        pre2.transform(X_te_ff),\n",
        "    )\n",
        "\n",
        "    pre3 = build_preprocessor(X_tr_ff, 3)\n",
        "    X3_tr, X3_val, X3_te = (\n",
        "        pre3.transform(X_tr_ff),\n",
        "        pre3.transform(X_val_ff),\n",
        "        pre3.transform(X_te_ff),\n",
        "    )\n",
        "\n",
        "    in_dim = X1_tr.shape[1]\n",
        "\n",
        "    # ========= Stage 1: I vs Rest =========\n",
        "    print(\"\\n-- Stage 1 (I vs Rest) --\")\n",
        "    y1_tr = build_stage1_labels(y_tr)\n",
        "    y1_val   = build_stage1_labels(y_val)\n",
        "    y1_te  = build_stage1_labels(y_test)\n",
        "\n",
        "    cw1 = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y1_tr), y=y1_tr)\n",
        "    cw1_dict = {int(cls): float(w) for cls, w in zip(np.unique(y1_tr), cw1)}\n",
        "\n",
        "    m1 = create_model(in_dim, 1, params1, is_binary=True)\n",
        "    history1 = m1.fit(X1_tr, y1_tr.values,\n",
        "           validation_data=(X1_val, y1_val.values),\n",
        "           epochs=params1[\"epochs\"],\n",
        "           batch_size=params1[\"batch_size\"],\n",
        "           callbacks=callbacks,\n",
        "           verbose=0,\n",
        "           class_weight=cw1_dict)\n",
        "\n",
        "    plot_history(history1)\n",
        "\n",
        "    # --- Threshold tuning on validation\n",
        "    p1_val = m1.predict(X1_val, verbose=0).ravel()\n",
        "    thresh1 = find_optimal_threshold(y1_val, p1_val)\n",
        "    #thresh1 = 0.55 This is the average threshold obtained from the 5 best performing runs\n",
        "    print(f\"Optimal threshold (Stage 1): {thresh1:.3f}\")\n",
        "\n",
        "    # --- Apply tuned threshold on test set\n",
        "    p1_te = m1.predict(X1_te, verbose=0).ravel()\n",
        "    pred1_te = (p1_te >= thresh1).astype(int)\n",
        "    print(classification_report(y1_te, pred1_te, digits=4, zero_division=0))\n",
        "    print(\"Balanced Accuracy:\", balanced_accuracy_score(y1_te, pred1_te))\n",
        "    cm1 = confusion_matrix(y1_te, pred1_te)\n",
        "    plot_confusion_matrix_relative(cm1, class_names=[\"Rest\", \"I\"], title=\"Stage 1 (I vs Rest)\")\n",
        "    accuracies.append(balanced_accuracy_score(y1_te, pred1_te))\n",
        "\n",
        "    # ========= Stage 2: DC vs Rest =========\n",
        "    print(\"\\n-- Stage 2 (DC vs Rest) --\")\n",
        "    mask2_tr, y2_tr = build_stage2_labels(y_tr)\n",
        "    mask2_val, y2_val = build_stage2_labels(y_val)\n",
        "    mask2_te, y2_te = build_stage2_labels(y_test)\n",
        "\n",
        "    X2_tr_m, X2_val_m, X2_te_m = X2_tr[mask2_tr.values], X2_val[mask2_val.values], X2_te[mask2_te.values]\n",
        "\n",
        "    cw2 = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y2_tr), y=y2_tr)\n",
        "    cw2_dict = {int(cls): float(w) for cls, w in zip(np.unique(y2_tr), cw2)}\n",
        "\n",
        "    m2 = create_model(in_dim, 2, params2, is_binary=True)\n",
        "    history2 = m2.fit(X2_tr_m, y2_tr,\n",
        "           validation_data=(X2_val_m, y2_val.values),\n",
        "           epochs=params2['epochs'],\n",
        "           batch_size=params2[\"batch_size\"],\n",
        "           callbacks=callbacks,\n",
        "           verbose=0,\n",
        "           class_weight=cw2_dict)\n",
        "\n",
        "    plot_history(history2)\n",
        "\n",
        "    # --- Threshold tuning on validation\n",
        "    p2_val = m2.predict(X2_val_m, verbose=0).ravel()\n",
        "    thresh2 = find_optimal_threshold(y2_val, p2_val)\n",
        "    if thresh2 < 0.2:\n",
        "        thresh2 = 0.2\n",
        "    print(f\"Optimal threshold (Stage 2): {thresh2:.3f}\")\n",
        "\n",
        "    # --- Apply tuned threshold on test set\n",
        "    p2_te = m2.predict(X2_te_m, verbose=0).ravel()\n",
        "    pred2_te = (p2_te >= thresh2).astype(int)\n",
        "    print(classification_report(y2_te, pred2_te, digits=4, zero_division=0))\n",
        "    print(\"Balanced Accuracy:\", balanced_accuracy_score(y2_te, pred2_te))\n",
        "    cm2 = confusion_matrix(y2_te, pred2_te)\n",
        "    plot_confusion_matrix_relative(cm2, class_names=[\"PID\", \"DC\"], title=\"Stage 2 (DC vs Rest)\")\n",
        "    accuracies.append(balanced_accuracy_score(y2_te, pred2_te))\n",
        "\n",
        "    # ========= Stage 3: Multiclass =========\n",
        "    print(\"\\n-- Stage 3 (Multiclass) --\")\n",
        "    mask3_tr, y3_tr = build_stage3_labels(y_tr)\n",
        "    mask3_val, y3_val = build_stage3_labels(y_val)\n",
        "    mask3_te, y3_te = build_stage3_labels(y_test)\n",
        "\n",
        "    X3_tr_m, X3_val_m, X3_te_m = X3_tr[mask3_tr.values], X3_val[mask3_val.values], X3_te[mask3_te.values]\n",
        "\n",
        "    #sm = SMOTE(random_state=17, k_neighbors=5)\n",
        "    #X3_tr_res, y3_tr_res = sm.fit_resample(X3_tr_m, y3_tr.values)\n",
        "\n",
        "    num_classes = 4\n",
        "    cw3 = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y3_tr), y=y3_tr)\n",
        "    cw3_dict = {int(cls): float(w) for cls, w in zip(np.unique(y3_tr), cw3)}\n",
        "\n",
        "    m3 = create_model(in_dim, 3, params3, is_binary=False)\n",
        "    history3 = m3.fit(X3_tr_m, y3_tr,\n",
        "           validation_data=(X3_val_m, y3_val.values),\n",
        "           epochs=params3[\"epochs\"],\n",
        "           batch_size=params3[\"batch_size\"],\n",
        "           callbacks=callbacks,\n",
        "           verbose=0,\n",
        "           class_weight=cw3_dict)\n",
        "\n",
        "    plot_history(history3)\n",
        "\n",
        "    p3_te = m3.predict(X3_te_m, verbose=0)\n",
        "    pred3_te_idx = np.argmax(p3_te, axis=1)\n",
        "    print(classification_report(y3_te, pred3_te_idx, digits=4, zero_division=0))\n",
        "    print(\"Balanced Accuracy:\", balanced_accuracy_score(y3_te, pred3_te_idx))\n",
        "    cm3 = confusion_matrix(y3_te, pred3_te_idx)\n",
        "    plot_confusion_matrix_relative(cm3, class_names=STAGE3_CLASSES, title=\"Stage 3 (Multiclass)\")\n",
        "    accuracies.append(balanced_accuracy_score(y3_te, pred3_te_idx))\n",
        "\n",
        "    # ========= Overall predictions (test set only) =========\n",
        "    pI_all  = m1.predict(X1_te, verbose=0).ravel()\n",
        "    pDC_all = m2.predict(X2_te, verbose=0).ravel()\n",
        "    pS3_all = m3.predict(X3_te, verbose=0)\n",
        "\n",
        "    final_probs = soft_gated_combine_probs(pI_all, pDC_all, pS3_all, thresh1, thresh2)\n",
        "    final_idx = np.argmax(final_probs, axis=1)\n",
        "    final_preds = [ALL_CLASSES[i] for i in final_idx]\n",
        "\n",
        "    print(\"\\n== Soft-Gated Overall (Test Set) ==\")\n",
        "    print(classification_report(y_test, final_preds, labels=ALL_CLASSES,\n",
        "                                target_names=ALL_CLASSES, digits=4, zero_division=0))\n",
        "    print(\"Balanced Accuracy:\", balanced_accuracy_score(y_test, final_preds))\n",
        "    cm_final = confusion_matrix(y_test, final_preds, labels=ALL_CLASSES)\n",
        "    plot_confusion_matrix_relative(cm_final, class_names=ALL_CLASSES, title=\"Final Soft-Gated Confusion Matrix\")\n",
        "    accuracies.append(balanced_accuracy_score(y_test, final_preds))\n",
        "\n",
        "    return final_preds, accuracies"
      ],
      "metadata": {
        "id": "V-aT1BMO_vop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VT7JECZQimfz"
      },
      "outputs": [],
      "source": [
        "params1 = {'units': 239, 'learning_rate': 0.0016, 'dropout_rate': 0.364, 'num_hidden_layers': 1, 'batch_size': 110, 'epochs': 46, 'l2_reg': 0.0039, 'activation': \"selu\", 'optimizer': \"sgd\"}\n",
        "#params2 = {'units': 167, 'learning_rate': 0.0054, 'dropout_rate': 0.3488, 'num_hidden_layers': 1, 'batch_size': 21, 'epochs': 50, 'l2_reg': 0.00612, 'activation': 'selu', 'optimizer': 'rmsprop'}\n",
        "params2 = {'units': 236, 'learning_rate': 0.0092, 'dropout_rate': 0.484, 'num_hidden_layers': 1, 'batch_size': 84, 'epochs': 59, 'l2_reg': 0.0018, 'activation': \"selu\", 'optimizer': \"sgd\"}\n",
        "params3 = {'units': 86, 'learning_rate': 0.01, 'dropout_rate': 0.2, 'num_hidden_layers': 3, 'batch_size': 71, 'epochs': 86, 'l2_reg': 0.000001, 'activation': \"selu\", 'optimizer': \"rmsprop\"}\n",
        "params4 = {'units': 150, 'learning_rate': 0.01, 'dropout_rate': 0.5, 'num_hidden_layers': 1, 'batch_size': 84, 'epochs': 88, 'l2_reg': 0.01, 'activation': \"selu\", 'optimizer': \"sgd\"}\n",
        "\n",
        "train = pd.read_csv('df_cluster.csv')\n",
        "test = pd.read_csv('df_cluster_VAL.csv')\n",
        "\n",
        "train = labelize(train)\n",
        "test = labelize(test)\n",
        "test.columns = train.columns # some column names have slighlty different names\n",
        "\n",
        "CORR_THRESHOLD = 0.9\n",
        "\n",
        "X_train = train.drop(columns=['IUIS', 'IUIS extended', 'PCODE','y'])\n",
        "y_train = train['y']\n",
        "X_test = test.drop(columns=['IUIS', 'IUIS extended', 'PCODE','y'])\n",
        "y_test = test['y']\n",
        "\n",
        "accs = []\n",
        "for i in range(10):\n",
        "    report, b_acc = run_cascade_TEST(X_train, y_train, X_test, y_test)\n",
        "    accs.append(b_acc)\n",
        "for element in accs:\n",
        "    element = [float(a) for a in element]\n",
        "    print(element)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9P3SkLEHuRj"
      },
      "outputs": [],
      "source": [
        "def run_multi_TEST(X_train, y_train, X_holdout, y_holdout):\n",
        "    \"\"\"\n",
        "    Train a multiclass model on a training set (with stratified 80/20 split for monitoring),\n",
        "    and evaluate once on the provided holdout set.\n",
        "    \"\"\"\n",
        "\n",
        "    # Encode labels\n",
        "    le = LabelEncoder()\n",
        "    y_train_enc = le.fit_transform(y_train)\n",
        "    y_holdout_enc = le.transform(y_holdout)\n",
        "    class_names = le.classes_\n",
        "\n",
        "    # ---- Split training into train/val (80/20 stratified)\n",
        "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=RANDOM_STATE)\n",
        "    tr_idx, val_idx = next(sss.split(X_train, y_train_enc))\n",
        "\n",
        "    X_tr_raw, X_val_raw = X_train.iloc[tr_idx].copy(), X_train.iloc[val_idx].copy()\n",
        "    y_tr, y_val = y_train_enc[tr_idx], y_train_enc[val_idx]\n",
        "\n",
        "    # ---- Feature filter\n",
        "    ff = FeatureFilter(corr_threshold=CORR_THRESHOLD)\n",
        "    ff.fit(X_tr_raw)\n",
        "    X_tr_ff, X_val_ff, X_te_ff = ff.transform(X_tr_raw), ff.transform(X_val_raw), ff.transform(X_holdout)\n",
        "\n",
        "    # ---- Preprocessing\n",
        "    pre4 = build_preprocessor(X_tr_ff, 4)\n",
        "    X_tr_prep, X_val_prep, X_te_prep = (\n",
        "        pre4.transform(X_tr_ff),\n",
        "        pre4.transform(X_val_ff),\n",
        "        pre4.transform(X_te_ff),\n",
        "    )\n",
        "    input_dim = X_tr_prep.shape[1]\n",
        "\n",
        "    # ---- Class weights\n",
        "    cw = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_tr), y=y_tr)\n",
        "    cw_dict = {cls: w for cls, w in zip(np.unique(y_tr), cw)}\n",
        "\n",
        "    # ---- Build and train model\n",
        "    model = create_model(input_dim, 4, params4, is_binary=False)\n",
        "    history = model.fit(\n",
        "        X_tr_prep, y_tr,\n",
        "        validation_data=(X_val_prep, y_val),\n",
        "        epochs=int(params4[\"epochs\"]),\n",
        "        batch_size=int(params4[\"batch_size\"]),\n",
        "        callbacks=callbacks,\n",
        "        verbose=0,\n",
        "        class_weight=cw_dict\n",
        "        )\n",
        "\n",
        "    # ---- Predictions on holdout set\n",
        "    y_pred_prob = model.predict(X_te_prep, verbose=1)\n",
        "    y_pred_idx = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "    # Decode back to string labels\n",
        "    y_ho_labels = le.inverse_transform(y_holdout_enc)\n",
        "    y_pred_labels = le.inverse_transform(y_pred_idx)\n",
        "\n",
        "    # ---- Reports\n",
        "    print(\"\\n== Holdout Evaluation ==\")\n",
        "    print(classification_report(y_ho_labels, y_pred_labels, labels=class_names, digits=4, zero_division=0))\n",
        "    print(\"Balanced Accuracy:\", balanced_accuracy_score(y_ho_labels, y_pred_labels))\n",
        "    cm = confusion_matrix(y_ho_labels, y_pred_labels, labels=class_names)\n",
        "    print(\"Confusion Matrix:\\n\", cm)\n",
        "    plot_confusion_matrix_relative(cm, class_names=class_names, title=\"Holdout Confusion Matrix\")\n",
        "\n",
        "    return {\"y_true\": pd.Series(y_ho_labels).reset_index(drop=True),\n",
        "            \"y_pred\": pd.Series(y_pred_labels).reset_index(drop=True)}, balanced_accuracy_score(y_ho_labels, y_pred_labels), history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqFBQuKGqSLh"
      },
      "outputs": [],
      "source": [
        "#params1 = {'units': 239, 'learning_rate': 0.0016, 'dropout_rate': 0.364, 'num_hidden_layers': 1, 'batch_size': 110, 'epochs': 46, 'l2_reg': 0.0039, 'activation': \"selu\", 'optimizer': \"sgd\"}\n",
        "#params2 = {'units': 236, 'learning_rate': 0.0092, 'dropout_rate': 0.484, 'num_hidden_layers': 1, 'batch_size': 84, 'epochs': 59, 'l2_reg': 0.0018, 'activation': \"selu\", 'optimizer': \"sgd\"}\n",
        "#params3 = {'units': 86, 'learning_rate': 0.01, 'dropout_rate': 0, 'num_hidden_layers': 3, 'batch_size': 71, 'epochs': 86, 'l2_reg': 0.000001, 'activation': \"selu\", 'optimizer': \"rmsprop\"}\n",
        "params4 = {'units': 150, 'learning_rate': 0.01, 'dropout_rate': 0.5, 'num_hidden_layers': 1, 'batch_size': 84, 'epochs': 88, 'l2_reg': 0.01, 'activation': \"selu\", 'optimizer': \"sgd\"}\n",
        "\n",
        "\n",
        "#params1 = {'units': 239, 'learning_rate': 0.0016, 'dropout_rate': 0.364, 'num_hidden_layers': 1, 'batch_size': 110, 'epochs': 46, 'l2_reg': 0.0039, 'activation': \"selu\", 'optimizer': \"sgd\"}\n",
        "#params2 = {'units': 236, 'learning_rate': 0.0092, 'dropout_rate': 0.484, 'num_hidden_layers': 1, 'batch_size': 84, 'epochs': 59, 'l2_reg': 0.0018, 'activation': \"selu\", 'optimizer': \"sgd\"}\n",
        "#params3 = {'units': 86, 'learning_rate': 0.01, 'dropout_rate': 0, 'num_hidden_layers': 3, 'batch_size': 71, 'epochs': 86, 'l2_reg': 0.000001, 'activation': \"selu\", 'optimizer': \"rmsprop\"}\n",
        "#params4 = {'units': 150, 'learning_rate': 0.01, 'dropout_rate': 0.5, 'num_hidden_layers': 1, 'batch_size': 84, 'epochs': 88, 'l2_reg': 0.01, 'activation': \"selu\", 'optimizer': \"sgd\"}\n",
        "\n",
        "train = pd.read_csv('df_cluster.csv')\n",
        "test = pd.read_csv('df_cluster_VAL.csv')\n",
        "\n",
        "train = labelize(train)\n",
        "test = labelize(test)\n",
        "test.columns = train.columns # some column names have slighlty different names\n",
        "\n",
        "CORR_THRESHOLD = 0.9\n",
        "\n",
        "X_train = train.drop(columns=['IUIS', 'IUIS extended', 'PCODE','y'])\n",
        "y_train = train['y']\n",
        "X_test = test.drop(columns=['IUIS', 'IUIS extended', 'PCODE','y'])\n",
        "y_test = test['y']\n",
        "\n",
        "accs = []\n",
        "for i in range(5):\n",
        "    report, b_acc, history = run_multi_TEST(X_train, y_train, X_test, y_test)\n",
        "    accs.append(float(b_acc))\n",
        "\n",
        "print(accs)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Ls_goHIYqQEd",
        "z0TFVGivvZIX",
        "uOjIqGo-qqNR",
        "4bxj1fWMcx4O",
        "OO5FJXui_-Yq",
        "tQFyFIAHh8is",
        "_AIFpXdpEQ20"
      ],
      "authorship_tag": "ABX9TyP1ARGnJiSOFp7DTvojfYwz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}